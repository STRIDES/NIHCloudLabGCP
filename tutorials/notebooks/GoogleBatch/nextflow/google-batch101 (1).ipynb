{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "988541e9-1343-4707-9998-b2da70e08349",
   "metadata": {},
   "source": [
    "# What is Google Batch?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881739bb-db17-467d-93ab-8b58ce70a5cd",
   "metadata": {},
   "source": [
    "Batch allows you to schedule, queue, and execute batch processing workloads on a VM instances. Batch provisions resources and manages capacity on your behalf, allowing your batch workloads to run at scale. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18aeb9e-1068-48de-85cf-710d204516b3",
   "metadata": {},
   "source": [
    "__What are tasks?__\n",
    "\n",
    "Tasks are actions or steps that will be executed by batch. You can edit how many tasks you have, resources (cpus and memory that each task will need, and how many should be run parallel to each other). \n",
    "\n",
    "__How does Batch differ from cloud Life Sciences?__\n",
    "\n",
    "You don't need to configure and manage third-party job schedulers, provision and deprovision resources, or request resources one zone at a time. To run a job, you specify parameters for the resources required for your workload, then Batch obtains resources and queues the job for execution. Batch provides native integration with other Google Cloud services to aid in the scheduling, execution, storage, and analysis of batch jobs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f0b370-0199-4550-a23d-5201bf4abfea",
   "metadata": {},
   "source": [
    "# 0. Batch Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f85dc7-aa30-482f-a128-e79bb9b91db4",
   "metadata": {},
   "source": [
    "Before using Batch first enable the __Batch, Compute Engine, and Cloud Logging__ APIs by searching each product and clicking <img src=\"batch_images/service_account_5.jpg\" width=\"50\" height=\"50\"> if you havent already.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a557257-6c56-4d0a-8511-98b488500192",
   "metadata": {},
   "source": [
    "Once the APIs are enabled you now need to add the following service account roles add the following roles to service account\n",
    "- Service Account Admin\n",
    "- Batch Agent Reporter \n",
    "- Storage Admin\n",
    "- Storage Object Admin\n",
    "- Batch Job Admin\n",
    "\n",
    "By going to navigation menu to __IAM & Admin__ then __Service Accounts__. \n",
    "\n",
    "<img src=\"batch_images/service_account_1.jpeg\" width=\"200\" height=\"200\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad515f2-38f8-4717-8bae-8b2dd5f1e9ec",
   "metadata": {},
   "source": [
    "You can create a new service account by clicking <img src=\"batch_images/service_account_2.jpeg\" width=\"200\" height=\"200\"> and call the the service account __\"batch service account\"__\n",
    "\n",
    "To add roles to your new service account click the edit icon <img src=\"batch_images/service_account_3.jpeg\" width=\"30\" height=\"30\">\n",
    "\n",
    "Then add the above roles through the filter bar \n",
    "\n",
    "<img src=\"batch_images/service_account_4.jpg\" width=\"300\" height=\"300\">\n",
    "\n",
    "Once the roles are added click __Save__\n",
    "\n",
    "__WARNING__: Please __do not create a service key__ if instructed by any tutorial. API keys are generally not considered secure; they are typically accessible to clients, making it easy for someone to steal an API key. Once the key is stolen, it has no expiration, so it may be used indefinitely, unless the project owner revokes or regenerates the key. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7dc517-5650-4da3-8c1d-1d65b7b93abe",
   "metadata": {},
   "source": [
    "# 1. Submit a job directly to Google Batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f291d9-1254-4f68-a030-cc518356c481",
   "metadata": {},
   "source": [
    "#### 1.1 Submitting a job through the console"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e1b2d2-d831-426e-90b0-cc232e39e7b2",
   "metadata": {},
   "source": [
    "Running a batch job through the console allows for a user-friendly view to input data and scripts and view the status of the jobs you created.\n",
    "\n",
    "Start by searching __'Batch'__ in the console search bar you should see a similar setting like this  \n",
    "<img src=\"batch_images/batch_start.png\" width=\"300\" height=\"300\">\n",
    "\n",
    "Near the upper left corner click <img src=\"batch_images/create.png\" width=\"50\" height=\"50\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05102f00-89e5-45a6-90a3-37bcea3e5c5b",
   "metadata": {},
   "source": [
    " \n",
    " The follow should appear on the screen\n",
    " \n",
    " <img src=\"batch_images/create_job_console.png\" width=\"300\" height=\"300\">\n",
    " \n",
    " This is where you can:\n",
    " - Label your job\n",
    " - Select a region and zone to excecute your job\n",
    " - Select your machine type (e.g. e2-medium)\n",
    " - Specify tasks by adding a script and/or specifiying a container to run the task in\n",
    " - Allocating resources for each task\n",
    " - Add storage volume"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f92fc3-89cc-4324-a55e-0c7d21b77b40",
   "metadata": {},
   "source": [
    "Once you have entered the settings for your batch job you can even view the full script that you would submit through the command line by clicking __'EQUIVALENT COMMAND LINE'__ next to __'CREATE'__ to see the following output. In the next section we will go in more depth of how to edit this script and submit your job through the command line. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e0f48a-0f0c-4c40-a653-9dd908fcd598",
   "metadata": {},
   "source": [
    " <img src=\"batch_images/Batch_command_line_console.png\" width=\"400\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806b6027-6b67-4fd2-aa40-7cf8379b908b",
   "metadata": {},
   "source": [
    "Once you run your job by clicking __'CREATE'__. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91509a5c-adba-43e7-93dd-c10b20d583b7",
   "metadata": {},
   "source": [
    "You can view the status of your job by looking at the __'Job List'__. Here you will see your job name, status, region, memory per task, machine type, date started and run time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff48826-ca98-42d0-984b-90af49e022db",
   "metadata": {},
   "source": [
    " <img src=\"batch_images/Job_l.png\" width=\"500\" height=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600fd131-ecc3-4f04-ba7f-5d1c51f667ea",
   "metadata": {},
   "source": [
    "By clicking the job name you can view more information of the jobs setting, resources applied, and logs by clicking  <img src=\"batch_images/log.png\" width=\"100\" height=\"100\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ce79ba-b156-4b8e-9c62-1bf92011a29c",
   "metadata": {},
   "source": [
    "### 1.2 Submitting a job through the command line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d64427-4a32-4d69-aa7f-8f57837614f1",
   "metadata": {},
   "source": [
    "To submit a batch job through the command line you first need to create a __json__ file this is your config file. You can use the attached hello world script as a template for your batch job."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180ec7c3-32fe-44b6-8328-37ab8f5f6fc5",
   "metadata": {},
   "source": [
    "The hello world script will look like this:\n",
    "    \n",
    "<img src=\"batch_images/script.png\" width=\"600\" height=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758796c6-20a4-4c78-8fff-9c06944640bc",
   "metadata": {},
   "source": [
    "To submit the job enter:\n",
    "\n",
    "gcloud beta batch jobs submit _job-name_ \\\n",
    "--location _location that job should be submitted in_ \\\n",
    "--config _the location of your json file_\n",
    "\n",
    "You can see the output shows our json file and the first line tell us if it was successful.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bec500-2332-4f8b-b7a1-3e376f56bada",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!gcloud beta batch jobs submit example-script-job \\\n",
    "  --location us-central1 \\\n",
    "  --config batch/hello-world-script.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cccbc9-220d-4d1b-9793-2140a960916b",
   "metadata": {},
   "source": [
    "To add a __bucket/storage__ to hold outputs from your batch job you can add a __volumes__ block in your config script. This block will be a sub-block apart of the __runnables__ block (see the hello-world-script). You can add any of your existing buckets and ask that they be mounted to the jobs container.\n",
    "\n",
    "```\n",
    "\"volumes\": [\n",
    "            {\n",
    "                \"gcs\": {\n",
    "                \"remotePath\": \"test-bucket\"\n",
    "                },\n",
    "                \"mountPath\": \"/mnt/share\"\n",
    "            }\n",
    "            ]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac817b47-e1cb-44d3-b3a3-47c20f475468",
   "metadata": {},
   "source": [
    "To change the __container__ instead of the default container your runnables block will look quite different.\n",
    "Instead of writing \"script\" you will need to identify the image name or address, the entrypoint, and any commands.\n",
    "\n",
    "```\n",
    "\"runnables\": [\n",
    "            {\n",
    "                \"container\": {\n",
    "                \"imageUri\": \"gcr.io/google-containers/busybox\",\n",
    "                \"entrypoint\": \"/bin/sh\",\n",
    "                \"commands\": [\n",
    "                    \"-c\",\n",
    "                    \"echo Hello world! This is task ${BATCH_TASK_INDEX}. This job has a total of ${BATCH_TASK_COUNT} tasks.\"\n",
    "                ]\n",
    "                }\n",
    "            }\n",
    "            ],\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5b9af0-c7c3-4cb7-bb75-15545c4647a7",
   "metadata": {},
   "source": [
    "## 2. Running Google Batch through Nextflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38c16e6-d979-4e74-9fb3-37fcce23cad5",
   "metadata": {},
   "source": [
    "Nextflow interacts with many different files to have a proper working workflow:\n",
    "\n",
    "- __Main file__: The main file is a .nf file that holds the processes and channels describing the input, output, a shell script of your commands, workflow which acts like a recipe book for nextflow, and/or conditions. For snakemake users this is equivalent to 'rules'.\n",
    "    - __Process__: Contains channels and scripts that can be executed in a Linux server like bash commands.\n",
    "    - __Channel__: Produces ways through which processes communicate to each other for example input and output are channels of value that point the process to where data is or should be located.\n",
    "- __Config file__: The .config file contains parameters, and multiple profiles. Each profile can contain a different executor type (e.g. LS API, conda, docker, etc.), memory or machine type, output directory, working directory and more!\n",
    "- __Docker file__: Contains dependencies and enviroments that is needed for the nextflow workflow to run.\n",
    "- __Schema file__: Schmema files are optional and are structured json files that contain information about the usage and commands that your workflow will excecute.You might have seen this when you run a command along with the flag '--help'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84df4f0-0aa8-4022-93c9-f616fab79902",
   "metadata": {},
   "source": [
    "Google Batch runs very similarly like Life Sciences through Nextflow the main differences are:\n",
    "- Need latest release of Nextflow from the edge channel (version 22.07.1-edge or later) to run google batch. We used the latest version: 22.10.4\n",
    "- Will need to create a new profile in your Nextflow config file \n",
    "    - the profile will be name __gbatch__\n",
    "    - executor name will be 'google-batch'\n",
    "    \n",
    "```\n",
    "profiles{\n",
    "  gbatch{\n",
    "      process.executor = 'google-batch'\n",
    "      process.machineType = 'n2-standard-16'\n",
    "      workDir = 'gs://BUCKETNAME/YOUR_WORKING_DIRECTORY' #Will store temporary files\n",
    "      google.location = 'us-central1'\n",
    "      google.region  = 'us-central1'\n",
    "      google.project = 'YOUR_PROJECT_ID'\n",
    "      params.outdir = 'gs://BUCKETNAME/YOUR_OUTPUT_DIRECTORY' #Will store your outputs, should be different than your working directory\n",
    "      }\n",
    "}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa9109e-0f1f-4397-b81c-b88f7076b561",
   "metadata": {},
   "source": [
    "Always remember to self-update Nextflow and export the google plugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6dbf709-f4f1-4693-b677-c48bc636e371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAPSULE: Downloading dependency org.multiverse:multiverse-core:jar:0.7.0wait .. Downloading nextflow dependencies. It may require a few seconds, please wait .. 2/3 KB   \n",
      "CAPSULE: Downloading dependency org.slf4j:jul-to-slf4j:jar:1.7.36\n",
      "CAPSULE: Downloading dependency org.codehaus.groovy:groovy-templates:jar:3.0.16\n",
      "CAPSULE: Downloading dependency io.nextflow:nf-httpfs:jar:23.04.0\n",
      "CAPSULE: Downloading dependency org.slf4j:jcl-over-slf4j:jar:1.7.36\n",
      "CAPSULE: Downloading dependency commons-io:commons-io:jar:2.11.0\n",
      "CAPSULE: Downloading dependency org.codehaus.jsr166-mirror:jsr166y:jar:1.7.0\n",
      "CAPSULE: Downloading dependency commons-codec:commons-codec:jar:1.15\n",
      "CAPSULE: Downloading dependency com.google.guava:listenablefuture:jar:9999.0-empty-to-avoid-conflict-with-guava\n",
      "CAPSULE: Downloading dependency ch.artecat.grengine:grengine:jar:3.0.0\n",
      "CAPSULE: Downloading dependency org.yaml:snakeyaml:jar:1.33\n",
      "CAPSULE: Downloading dependency com.beust:jcommander:jar:1.35\n",
      "CAPSULE: Downloading dependency jline:jline:jar:2.9\n",
      "CAPSULE: Downloading dependency ch.qos.logback:logback-core:jar:1.2.11\n",
      "CAPSULE: Downloading dependency com.github.zafarkhaja:java-semver:jar:0.9.0\n",
      "CAPSULE: Downloading dependency io.nextflow:nextflow:jar:23.04.0\n",
      "CAPSULE: Downloading dependency javax.mail:mail:jar:1.4.7\n",
      "CAPSULE: Downloading dependency io.nextflow:nf-commons:jar:23.04.0\n",
      "CAPSULE: Downloading dependency org.codehaus.groovy:groovy-json:jar:3.0.16\n",
      "CAPSULE: Downloading dependency org.eclipse.jgit:org.eclipse.jgit:jar:6.2.0.202206071550-r\n",
      "CAPSULE: Downloading dependency com.google.code.findbugs:jsr305:jar:3.0.2\n",
      "CAPSULE: Downloading dependency org.codehaus.groovy:groovy:jar:3.0.16\n",
      "CAPSULE: Downloading dependency commons-lang:commons-lang:jar:2.6\n",
      "CAPSULE: Downloading dependency org.iq80.leveldb:leveldb-api:jar:0.12\n",
      "CAPSULE: Downloading dependency org.codehaus.gpars:gpars:jar:1.2.1\n",
      "CAPSULE: Downloading dependency ch.qos.logback:logback-classic:jar:1.2.11\n",
      "CAPSULE: Downloading dependency org.slf4j:log4j-over-slf4j:jar:1.7.36\n",
      "CAPSULE: Downloading dependency com.google.guava:guava:jar:31.1-jre\n",
      "CAPSULE: Downloading dependency org.objenesis:objenesis:jar:2.1\n",
      "CAPSULE: Downloading dependency com.esotericsoftware.kryo:kryo:jar:2.24.0\n",
      "CAPSULE: Downloading dependency org.slf4j:slf4j-api:jar:1.7.36\n",
      "CAPSULE: Downloading dependency com.google.errorprone:error_prone_annotations:jar:2.11.0\n",
      "CAPSULE: Downloading dependency org.apache.ivy:ivy:jar:2.3.0\n",
      "CAPSULE: Downloading dependency org.codehaus.groovy:groovy-nio:jar:3.0.16\n",
      "CAPSULE: Downloading dependency dev.failsafe:failsafe:jar:3.1.0\n",
      "CAPSULE: Downloading dependency com.google.j2objc:j2objc-annotations:jar:1.3\n",
      "CAPSULE: Downloading dependency javax.activation:activation:jar:1.1.1\n",
      "CAPSULE: Downloading dependency org.codehaus.groovy:groovy-xml:jar:3.0.16\n",
      "CAPSULE: Downloading dependency org.jsoup:jsoup:jar:1.15.3\n",
      "CAPSULE: Downloading dependency org.pf4j:pf4j:jar:3.4.1\n",
      "CAPSULE: Downloading dependency org.iq80.leveldb:leveldb:jar:0.12\n",
      "CAPSULE: Downloading dependency com.google.guava:failureaccess:jar:1.0.1\n",
      "CAPSULE: Downloading dependency com.googlecode.javaewah:JavaEWAH:jar:1.1.13\n",
      "CAPSULE: Downloading dependency com.google.code.gson:gson:jar:2.2.4\n",
      "CAPSULE: Downloading dependency org.checkerframework:checker-qual:jar:3.12.0\n",
      "CAPSULE: Downloading dependency org.pf4j:pf4j-update:jar:2.3.0\n",
      "                                                                          \n",
      "      N E X T F L O W\n",
      "      version 23.04.0 build 5857\n",
      "      created 01-04-2023 21:09 UTC \n",
      "      cite doi:10.1038/nbt.3820\n",
      "      http://nextflow.io\n",
      "\n",
      "\n",
      "Nextflow installation completed. Please note:\n",
      "- the executable file `nextflow` has been created in the folder: ..\n",
      "- you may complete the installation by moving it to a directory in your $PATH\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!export NXF_MODE=google\n",
    "!./nextflow self-update"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74e67c7-8bab-49ee-92c9-f4f187bf3135",
   "metadata": {},
   "source": [
    "Once you have your config file set we can run a hello world script to see it works by adding the __-profile__ command to say **gbatch** and the using the __-c__ command to write the location of your config file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ee3618-6983-4a00-9fb6-ee691d4e2068",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!sudo nextflow run https://github.com/nextflow-io/hello -profile gbatch -c nextflow.config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4150d7c2-4d50-45d8-ba78-673ab9eaff02",
   "metadata": {},
   "source": [
    "# Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbfb0fb-a66b-4231-99c9-190ca76f6aeb",
   "metadata": {},
   "source": [
    "Now we will run the nf-core RNAseq analysis using the test dataset. This analysis even when using the test data still take ~1hr to run. If this process ends in a error you can use the -resume flag to pick back up where it stopped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9300678-4cd0-4fde-aa10-cbc647dd3e14",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#G Batch RNA test\n",
    "!./nextflow run nf-core/rnaseq -r 3.8.1 -c nextflow.config -profile test,gbatch -resume"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d31829b-304d-4bb6-8bc4-66594482550e",
   "metadata": {},
   "source": [
    "## Real Data with Methylseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fe7c32-48b5-4d95-8fda-62fe4445ad52",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Real Data G Batch\n",
    "!./nextflow run nf-core/methylseq \\\n",
    "    -r 1.6.1 \\\n",
    "    --input 'SRR067701.fastq.gz' \\\n",
    "    --genome GRCh37 \\\n",
    "    --single_end \\\n",
    "    --max_cpus 32 \\\n",
    "    --max_memory '110.GB' \\\n",
    "    -c nextflow.config \\\n",
    "    -profile gbatch \\\n",
    "    -resume"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f95c41-464d-497c-b288-cd7bbe558d62",
   "metadata": {},
   "source": [
    "## Troubleshooting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dba88d3-5e41-43e6-8d36-85b4db6809ad",
   "metadata": {
    "tags": []
   },
   "source": [
    "Some of the nf-core tools require extra parameters:\n",
    "- If you receive a error of 'quota exceeded' error you can increase your boot disk size to the gbatch profile within your config file using the google.batch.bootDiskSize parameter (e.g., google.batch.bootDiskSize = 100.GB)\n",
    "- Some errors show that a tool could not be used, was not installed, or gives a error that doesn't really explain the reason for why the process stop you can try to increase the process time on your profile by using the process.time parameter (e.g., process.time = '2h')\n",
    "- If you receive a error like below using the new release of Nextflow should fix this v23.04.0 or later\n",
    "```\n",
    "Caused by:\n",
    "  Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@49b3a025[Not completed, task = java.util.concurrent.Executors$RunnableAdapter@2e0ceb8c[Wrapped task = TrustedListenableFutureTask@25c1396d[status=PENDING, info=[task=[running=[NOT STARTED YET], com.google.api.gax.rpc.AttemptCallable@2db57b9a]]]]] rejected from java.util.concurrent.ScheduledThreadPoolExecutor@aa6214[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]\n",
    "\n",
    "```\n",
    "- adding the -log parameter on the command line will help produce a log file that will help to troubleshoot other errors like so: \n",
    "`./nextflow -log DIRECTORY_NAME/nextflow.log run <process name>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80fb010-5152-42ae-954a-ecf06f388405",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "r-cpu.4-1.m97",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/r-cpu.4-1:m97"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

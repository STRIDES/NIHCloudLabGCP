{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2edc6187-82ae-44e2-852f-2ad2712c93aa",
   "metadata": {},
   "source": [
    "# Creating a Google Drive Chatbot on GCP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ffa179-9f88-490a-8a4d-2e4ab7b5996b",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a820eea-1538-4f40-86c4-eb14fe09e127",
   "metadata": {},
   "source": [
    "This tutorial is based on Google own Retrieval-Augmented Generation (RAG) API doumentation you can find [here](https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/rag-api)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7314b115-9433-460d-b275-78aa50f0a858",
   "metadata": {},
   "source": [
    "Vertex AI's **Retrieval-Augmented Generation (RAG) API** is a package that follows the RAG technique to a process that enhances the capabilities of large language models (LLMs) following the steps below.\n",
    "\n",
    "First **ingest/intake data** from different data sources like local files, Cloud Storage, and Google Drive. Second **transform the data** by splitting it into chunks to allow better retrieval of related information to your questions, lower risk of the model having hallucinations, and decrease the amount of tokens that are used. Third **embedding the text** meaning the words or pieces of text will be represented by a number that states the relationship it has with other text, how similar they are. Fourth **indexing the data** by creating knowledge bases or **corpus** that will store the chunks and embeddings and be given ids to be queried and referenced from. Fifth now that our knowledge base set up we can now **retrieve relevant information** from it based on the question or query the user provides. Sixth the retrieved information, this being only the relevant chunks of data, is then given to the model for it to **generate a response** to the users question.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d01e74b-b5b4-4be9-b16e-ec55419318ef",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbd13e7-afc9-416b-94dc-418a93e14587",
   "metadata": {},
   "source": [
    "We assume you have access to **Vertex AI** and Google Drive and have enabled the APIs. If not go to the console then `APIs & Services > Enabled APIs & Services` search for **'Google Drive API'** then click 'Enable'. do the same for Vertex AI.\n",
    "\n",
    "In this tutorial we will be using Google **gemini-2.0-flash** which doesn't need to be deployed but if you would like to use another model you choose one from the **Model Garden** using the console which will allow you to add a model to your model registry, create an endpoint (or use an existing one), and deploy the model all in one step. \n",
    "\n",
    "The last thing before we begin will to create a **Vertex AI RAG Data Service Agent** service account by going to `IAM` on the console then check mark **Include Google-provided role grant** if it not listed there then click grant access and add Vertex AI RAG Data Service Agent as a role."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c54262-ad81-455a-b0ee-47c859cee94a",
   "metadata": {},
   "source": [
    "## Learning objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecea2ad-7c65-4367-87e1-b021167c3a1d",
   "metadata": {},
   "source": [
    "For this tutorial we are creating a chatbot that will answer questions by gathering information from documents we have provided via Google Drive. The model we will be using today is a pretrained 'Gemini' model from GCP.\n",
    "\n",
    "This tutorial will go over the following topics:\n",
    "- Introducing RAG\n",
    "- Creating a Vertex AI RAG Corpus\n",
    "- Connecting our model to the RAG corpus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3e3ab1-5f7e-4028-a66f-9619926a2afd",
   "metadata": {},
   "source": [
    "## Get started"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9316f4ae-06e2-4a5f-b4c8-7180cdbc38a3",
   "metadata": {},
   "source": [
    "### Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed412af0-1e5f-4250-acc5-df46632802b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --upgrade google-api-python-client vertexai unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aeaa4f6-5cd5-4cc7-a710-97a6122fc9e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from vertexai.preview import rag\n",
    "from vertexai.preview.generative_models import GenerativeModel, Tool\n",
    "import vertexai\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5a8ea8-64f7-42fd-a08d-00f5ef674a07",
   "metadata": {},
   "source": [
    "### Enter variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87f5359-e574-4a62-bc9f-6ae4545a2080",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "project_id = \"<PROJECT_ID>\"\n",
    "display_name = \"<RAG_CORPUS_NAME>\"\n",
    "location = \"<REGION>\"#Please ensure that you are using a region that supports the creation of a RAG Corpus (e.g. us-central1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02053f4d-fad7-44ab-a7c3-cfa1c218240f",
   "metadata": {},
   "source": [
    "### Optional - Download articles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1c9de7-4a06-4f85-b9ff-c8c9e51f8c70",
   "metadata": {},
   "source": [
    "For this tutorial we will be downloading scientific articles from the [NIH RECOVER program](https://recovercovid.org/publications), which our model will then use as references to answer our questions about COVID. If you have your own file on your drive feel free to use those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b4c948-749d-44c3-abfa-60c8bc1f07a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#urls list of articles\n",
    "articles_urls = ['https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10781091/pdf/pone.0285645.pdf', \n",
    "                 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10219649/pdf/elife-86014.pdf',\n",
    "                 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10734909/pdf/pone.0285351.pdf',\n",
    "                 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10684592/pdf/41598_2023_Article_47655.pdf', \n",
    "                 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10601201/pdf/12889_2023_Article_16916.pdf',\n",
    "                 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10516599/pdf/elife-86043.pdf',\n",
    "                 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10620090/pdf/41586_2023_Article_6651.pdf',\n",
    "                 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10414557/pdf/pone.0289774.pdf',\n",
    "                 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10355333/pdf/aids-37-1565.pdf',\n",
    "                 'https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10289397/pdf/pone.0286297.pdf']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a3508d-67c8-41a2-a1e1-8d7f4f024c7d",
   "metadata": {},
   "source": [
    "Now well use a for loop to run `subprocess.run` to download each article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d49432-cf03-4f19-aa82-ef7f8bad5bde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "for url in articles_urls:\n",
    "    subprocess.run(f'wget --user-agent=\"Chrome\" {url}', shell=True, executable=\"/bin/bash\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57690af-e7ed-45fc-9645-bbf05c0f550e",
   "metadata": {},
   "source": [
    "Create a folder within your drive and upload these docs into your new drive folder. If you are using Jupyter Lab you can download the docs by right clicking them in the File Browser and selecting download. \n",
    "\n",
    "Then you will need to go to **IAM** on the console, check mark where it says **Include Google-provided role grants**, and copy the principcal email address with the **Vertex AI RAG Data Service Agent** role.\n",
    "\n",
    "![gdrive1](../../images/gdrive1.png)\n",
    "\n",
    "Then go to your Google Drive and share the folder you just created with that email address and add **Viewer permissions**.\n",
    "![gdrive2](../../images/gdrive2.png)\n",
    "![gdrive1.5](../../images/gdrive1.5.png)\n",
    "![gdrive3](../../images/gdrive3.png)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39f8a66-200d-4575-89da-981aa3bc94ea",
   "metadata": {},
   "source": [
    "### Setting up a RAG Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c75899-9eea-4fa8-99ed-2415e3cee973",
   "metadata": {},
   "source": [
    "Initialize Vertex AI API once per session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639352c6-a62a-4ed8-a04e-cd5fd35549d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vertexai.init(project=project_id, location=location)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f392961a-397c-4a3d-84d7-24905e21bbad",
   "metadata": {},
   "source": [
    "Create your RAG Corpus running the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca5ef4e-1523-4308-96ab-7372733885e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create RagCorpus\n",
    "rag_corpus = rag.create_corpus(display_name=display_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1875c023-0ae0-42d3-a1d2-ce5f7866afbd",
   "metadata": {},
   "source": [
    "You can view the name of your corpus which we will us to upload our files from Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ceab1af-caa5-41a6-b6c8-ea58578a8b02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(rag_corpus.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4858d0-2c05-46b6-9fac-846a7c76f885",
   "metadata": {},
   "source": [
    "### Importing and uploading files to RAG Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8d4e09-2ff3-4fd0-b26d-1e8536c42776",
   "metadata": {},
   "source": [
    "Enter in the Google Drive folder URI you would like to upload to the corpus. Be sure to format the URI like so adding in that extra `/d` bit: `https://drive.google.com/drive/d/folders/<FOLDER_ID>`. You can also add to the list paths to local files and buckets (format using `gs://`) to be added to the corpus all at once with your drive folder.\n",
    "\n",
    "For local files use the command `upload_files` instead.\n",
    "\n",
    "You can also control the size of the chunks and how much text should overlap in each chunk (this helps the model make a concise conclusion)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af311785-281f-4ba0-a5f9-c991d39b72ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import Files to the RagCorpus\n",
    "paths = [\"https://drive.google.com/drive/folders/11RWaO4LulNsyeJi-zohBObH3LtUGoqhn?usp=sharing\"]\n",
    "\n",
    "response = rag.import_files(\n",
    "    rag_corpus.name,\n",
    "    paths,\n",
    "    chunk_size=512,  \n",
    "    chunk_overlap=100\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c51a18-e78a-4339-adfa-e2b081944d88",
   "metadata": {},
   "source": [
    "Let check what files have been uploaded to our corpus!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a32b138-7ce8-49a7-80eb-fca6a0d6b4f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#list files in corpus\n",
    "files = rag.list_files(corpus_name=rag_corpus.name)\n",
    "for file in files:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f30576f-7a9d-4d25-818f-48a76a400928",
   "metadata": {},
   "source": [
    "We can now send our query to the corpus to view which relevant chunks it will send back. Notice the variable **similarity_top_k** this determine how many chunks we want to retrieve from our corpus. For this tutorial we are asking to retrieve the top 10 relevant chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df56d730-87b0-4296-b2d2-1b2ed90a2d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is Long Covid?\"\n",
    "\n",
    "# Direct context retrieval\n",
    "response = rag.retrieval_query(\n",
    "    rag_corpora=[rag_corpus.name],\n",
    "    text=query,\n",
    "    similarity_top_k=10,\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f092c7-3f85-48a2-889f-4b5aec112ac1",
   "metadata": {},
   "source": [
    "### Generating a reponse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a122f7-0734-45e2-b93c-c93eebfbe45b",
   "metadata": {},
   "source": [
    "Now we can create a RAG retrieval tool that will allow us to connect our model to 1 corpus to retrieval relevant data from. Notice we are using **gemini-2.0-flash**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36100bfe-9499-4515-b297-9244dd632e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhance generation\n",
    "# Create a RAG retrieval tool\n",
    "rag_retrieval_tool = Tool.from_retrieval(\n",
    "    retrieval=rag.Retrieval(\n",
    "        source=rag.VertexRagStore(\n",
    "            rag_corpora=[rag_corpus.name],  # Currently only 1 corpus is allowed.\n",
    "            similarity_top_k=3,\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "# Create a gemini-pro model instance\n",
    "rag_model = GenerativeModel(\n",
    "    model_name=\"gemini-2.0-flash\", tools=[rag_retrieval_tool]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27de55da-a87e-4b39-ba6a-fb692953a14a",
   "metadata": {},
   "source": [
    "Finally, we can submit a question to our model to generate a response based on the information it receives from our corpus!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e89c4ce-437a-4183-8e4c-688be2a5faee",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is Long Covid?\"\n",
    "# Generate response\n",
    "response = rag_model.generate_content(question)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc20374e-f8f2-474b-9cf5-e7ce18d62e22",
   "metadata": {},
   "source": [
    "### Put it all together!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4a99cc-78d3-44b3-bc74-dc9b6463ca8c",
   "metadata": {},
   "source": [
    "Now lets put it all together as a function to better allow you to add this process to other scripts!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19232c7e-88c5-4897-bff8-ddba161aaa0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertexai.init(project=project_id, location=location) #only need to run once\n",
    "\n",
    "def create_rag(display_name):\n",
    "    rag_corpus = rag.create_corpus(display_name=display_name)\n",
    "    return rag_corpus.name\n",
    "\n",
    "def file_upload(paths, rag_corpus_name):\n",
    "    response = rag.import_files(\n",
    "    rag_corpus_name,\n",
    "    [paths],\n",
    "    chunk_size=512,  \n",
    "    chunk_overlap=100\n",
    ")\n",
    "\n",
    "def generate_response(question, rag_corpus_name):\n",
    "    rag_retrieval_tool = Tool.from_retrieval(\n",
    "    retrieval=rag.Retrieval(\n",
    "        source=rag.VertexRagStore(\n",
    "            rag_corpora=[rag_corpus_name],  # Currently only 1 corpus is allowed.\n",
    "            similarity_top_k=3,\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "    # Create a gemini-pro model instance\n",
    "    rag_model = GenerativeModel(\n",
    "        model_name=\"gemini-2.0-flash\", tools=[rag_retrieval_tool]\n",
    "    )\n",
    "    response = rag_model.generate_content(question)\n",
    "    \n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f875487d-c12d-4b18-bd4d-c143cbe3160b",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec6e5f4-7d69-4736-a441-712a797299e1",
   "metadata": {},
   "source": [
    "You have just created a Google Drive Chatbot by creating and utilizing a RAG corpus from Vertex AI to retrieve relevant information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a178c1c6-368a-48c5-8beb-278443b685a2",
   "metadata": {},
   "source": [
    "## Clean Up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec06a34-dc47-453f-b519-424804fa2748",
   "metadata": {},
   "source": [
    "**Warning:** Dont forget to delete the resources we just made to avoid accruing additional costs such as buckets, the RAG Corpus, and if needed your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c307bb17-757a-4579-a0d8-698eb1bb3f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete RAG Corpus\n",
    "rag.delete_corpus(name=rag_corpus.name)\n",
    "print(f\"Corpus {rag_corpus.name} deleted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280cea0a-a8fc-494e-8ce4-afb65847a222",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete bucket (if applicable)\n",
    "!gcloud storage rm --recursive gs://{bucket}/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6928d95d-d7ec-43f6-9135-79fcfc9520d9",
   "metadata": {},
   "source": [
    "If you have imported a model and deployed it don't forget to delete the model from the Model Registry and delete the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61a78f9-6e8b-4897-90ce-54e6268773f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m129",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m129"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

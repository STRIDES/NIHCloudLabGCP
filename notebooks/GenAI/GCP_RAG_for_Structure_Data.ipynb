{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e38b3f2-2b29-4788-a29a-f9e5d10f8365",
   "metadata": {},
   "source": [
    "##### __Skill Level:__ <span style=\"color:blue\">Intermediate</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0533e3-4fbd-47b1-8458-fd193bcb263f",
   "metadata": {},
   "source": [
    "# Creating a Chatbot for Structured Data using BigQuery to implement RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cf4b02-6422-4a48-882c-c00315e34c8a",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7870dd-09e0-4f6a-91a9-7c30529af720",
   "metadata": {},
   "source": [
    "Generative AI (GenAI) represents a transformative technology capable of producing human-like text, images, code, and various other types of content. While much of the focus has been on unstructured data—such as PDFs, text documents, image files, and websites—many GenAI implementations rely on a parameter called \"top K.\" This algorithm retrieves only the highest-scoring pieces of content relevant to a user's query, which can be limiting. Users seeking insights from structured data formats like CSV and JSON often require access to all relevant occurrences, rather than just a subset.\n",
    "\n",
    "In this tutorial, we use a RAG agent together with a VertexAI chat model gemini-1.5-pro to query the BigQuery table. A Retrieval Augmented Generation (RAG) agent is a key part of a RAG application that enhances the capabilities of the large language models (LLMs) by integrating external data retrieval. AI agents empower LLMs to interact with the world through actions and tools. The agent connects to BigQuery, runs the query, and then sends the results to the model. The model processes the data and generates the final output that it is displayed for the user.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d513a9fe-1ac4-4610-b53c-6696e461f828",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdb09aa-73d6-4cee-b3e7-5d6b243e3d58",
   "metadata": {},
   "source": [
    "In this tutorial, we will be using Google Gemini Pro 1.5, which does not require deployment. However, if you prefer to use a different model, you can select one from the Model Garden via the console. This will allow you to add the model to your registry, create an endpoint (or utilize an existing one), and deploy the model—all in a single step. Here is a link for more information: [model deployment](https://cloud.google.com/vertex-ai/docs/general/deployment).\n",
    "\n",
    "Before we begin, you'll need to create a Vertex AI RAG Data Service Agent service account. To do this, go to the IAM section of the console. Ensure you check the box for \"Include Google-provided role grant.\" If the role is not listed, click \"Grant Access\" and add \"Vertex AI RAG Data Service Agent\" as a role. Additionally, to create datasets and tables in BigQuery, the user must have the __bigquery.datasets.create__ and __bigquery.tables.create__ permissions.\n",
    "\n",
    "We are using a e2-standard-4 (Efficient Instance: 4 vCPUs, 16 GB RAM) for this tutorial. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb24716-0db8-462f-8faa-0b8ad9d61feb",
   "metadata": {},
   "source": [
    "## Learning objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5216a43-31ee-4c3e-821a-4b81f4be8e54",
   "metadata": {},
   "source": [
    "In this tutorial you will learn about:\n",
    "- How to set up a BigQuery dataset and a table.\n",
    "- How to load data to a BigQuery table.\n",
    "- How to use the langchain ChatVertexAI agent to extract information from the table. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348910aa-9802-4318-8fcb-86603158923b",
   "metadata": {},
   "source": [
    "## Pricing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dca31b2-880d-4cbc-bf76-ede96998e371",
   "metadata": {},
   "source": [
    "If you are following this tutorial in one sitting it will cost ~$0.80 . Completing the process in multiple sessions or using a method different from the tutorial may result in increased costs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d9e3ee-1c7e-4baa-a818-c13330c665dd",
   "metadata": {},
   "source": [
    "## Get Started"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137defcd-fd2b-421d-9b2e-fe2b878fb325",
   "metadata": {},
   "source": [
    "### Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55c14a38-ba51-466d-90b5-1512f5a7fae0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-bigquery in /opt/conda/lib/python3.10/site-packages (3.31.0)\n",
      "Requirement already satisfied: google-api-core<3.0.0,>=2.11.1 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery) (2.24.2)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery) (2.38.0)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery) (2.4.3)\n",
      "Requirement already satisfied: google-resumable-media<3.0.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery) (2.7.2)\n",
      "Requirement already satisfied: packaging>=24.2.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery) (24.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery) (2.9.0.post0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery) (2.32.3)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core<3.0.0,>=2.11.1->google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery) (1.69.2)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /opt/conda/lib/python3.10/site-packages (from google-api-core<3.0.0,>=2.11.1->google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery) (3.20.3)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /opt/conda/lib/python3.10/site-packages (from google-api-core<3.0.0,>=2.11.1->google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery) (1.26.1)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery) (1.71.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery) (1.49.0rc1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-bigquery) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-bigquery) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-bigquery) (4.9)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.10/site-packages (from google-resumable-media<3.0.0,>=2.0.0->google-cloud-bigquery) (1.7.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.8.2->google-cloud-bigquery) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.21.0->google-cloud-bigquery) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.21.0->google-cloud-bigquery) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.21.0->google-cloud-bigquery) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.21.0->google-cloud-bigquery) (2025.1.31)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-cloud-bigquery) (0.6.1)\n",
      "Collecting gcloud\n",
      "  Downloading gcloud-0.18.3.tar.gz (454 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: httplib2>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from gcloud) (0.22.0)\n",
      "Requirement already satisfied: googleapis-common-protos in /opt/conda/lib/python3.10/site-packages (from gcloud) (1.69.2)\n",
      "Requirement already satisfied: oauth2client>=2.0.1 in /opt/conda/lib/python3.10/site-packages (from gcloud) (4.1.3)\n",
      "Requirement already satisfied: protobuf!=3.0.0.b2.post1,>=3.0.0b2 in /opt/conda/lib/python3.10/site-packages (from gcloud) (3.20.3)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from gcloud) (1.17.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /opt/conda/lib/python3.10/site-packages (from httplib2>=0.9.1->gcloud) (3.2.3)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /opt/conda/lib/python3.10/site-packages (from oauth2client>=2.0.1->gcloud) (0.6.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /opt/conda/lib/python3.10/site-packages (from oauth2client>=2.0.1->gcloud) (0.4.2)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from oauth2client>=2.0.1->gcloud) (4.9)\n",
      "Building wheels for collected packages: gcloud\n",
      "  Building wheel for gcloud (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gcloud: filename=gcloud-0.18.3-py3-none-any.whl size=602982 sha256=0a9c19da69ae0ae80fb3170b51ddfb53038a35aefa651421dfba55b49c4e6771\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/7c/30/88/5017af921da3a33af785f0d0fd3e944b845bc62a445a2c2f69\n",
      "Successfully built gcloud\n",
      "Installing collected packages: gcloud\n",
      "Successfully installed gcloud-0.18.3\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.3.24-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.55 (from langchain)\n",
      "  Downloading langchain_core-0.3.56-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langsmith<0.4,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.3.38-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.11.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.0.40)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (6.0.2)\n",
      "Collecting async-timeout<5.0.0,>=4.0.0 (from langchain)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.55->langchain) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.55->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/conda/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.55->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /opt/conda/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.55->langchain) (4.13.0)\n",
      "Collecting httpx<1,>=0.23.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading orjson-3.10.17-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
      "Requirement already satisfied: greenlet>=1 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.55->langchain) (3.0.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
      "Downloading langchain-0.3.24-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading langchain_core-0.3.56-py3-none-any.whl (437 kB)\n",
      "Downloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
      "Downloading langsmith-0.3.38-py3-none-any.whl (359 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading orjson-3.10.17-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (132 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: orjson, h11, async-timeout, requests-toolbelt, httpcore, httpx, langsmith, langchain-core, langchain-text-splitters, langchain\n",
      "  Attempting uninstall: h11\n",
      "    Found existing installation: h11 0.14.0\n",
      "    Uninstalling h11-0.14.0:\n",
      "      Successfully uninstalled h11-0.14.0\n",
      "  Attempting uninstall: async-timeout\n",
      "    Found existing installation: async-timeout 5.0.1\n",
      "    Uninstalling async-timeout-5.0.1:\n",
      "      Successfully uninstalled async-timeout-5.0.1\n",
      "  Attempting uninstall: requests-toolbelt\n",
      "    Found existing installation: requests-toolbelt 0.10.1\n",
      "    Uninstalling requests-toolbelt-0.10.1:\n",
      "      Successfully uninstalled requests-toolbelt-0.10.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "kfp 2.5.0 requires requests-toolbelt<1,>=0.8.0, but you have requests-toolbelt 1.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed async-timeout-4.0.3 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 langchain-0.3.24 langchain-core-0.3.56 langchain-text-splitters-0.3.8 langsmith-0.3.38 orjson-3.10.17 requests-toolbelt-1.0.0\n",
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.3.23-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.56 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (0.3.56)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.24 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (0.3.24)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (2.0.40)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (3.11.14)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (9.0.0)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
      "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (0.3.38)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (2.1.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /opt/conda/lib/python3.10/site-packages (from langchain<1.0.0,>=0.3.24->langchain-community) (0.3.8)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/conda/lib/python3.10/site-packages (from langchain<1.0.0,>=0.3.24->langchain-community) (2.11.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.56->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/conda/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.56->langchain-community) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /opt/conda/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.56->langchain-community) (4.13.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.17)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.4.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (2025.1.31)\n",
      "Requirement already satisfied: greenlet>=1 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
      "Requirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.56->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.24->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.24->langchain-community) (2.33.0)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n",
      "Downloading langchain_community-0.3.23-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Installing collected packages: mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-community\n",
      "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-community-0.3.23 marshmallow-3.26.1 mypy-extensions-1.1.0 pydantic-settings-2.9.1 typing-inspect-0.9.0\n",
      "Requirement already satisfied: pandas-gbq in /opt/conda/lib/python3.10/site-packages (0.28.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from pandas-gbq) (75.8.2)\n",
      "Requirement already satisfied: db-dtypes<2.0.0,>=1.0.4 in /opt/conda/lib/python3.10/site-packages (from pandas-gbq) (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.18.1 in /opt/conda/lib/python3.10/site-packages (from pandas-gbq) (2.1.3)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /opt/conda/lib/python3.10/site-packages (from pandas-gbq) (2.2.3)\n",
      "Requirement already satisfied: pyarrow>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from pandas-gbq) (19.0.1)\n",
      "Requirement already satisfied: pydata-google-auth>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from pandas-gbq) (1.9.1)\n",
      "Requirement already satisfied: google-api-core<3.0.0dev,>=2.10.2 in /opt/conda/lib/python3.10/site-packages (from pandas-gbq) (2.24.2)\n",
      "Requirement already satisfied: google-auth>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from pandas-gbq) (2.38.0)\n",
      "Requirement already satisfied: google-auth-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from pandas-gbq) (1.2.1)\n",
      "Requirement already satisfied: google-cloud-bigquery<4.0.0dev,>=3.4.2 in /opt/conda/lib/python3.10/site-packages (from pandas-gbq) (3.31.0)\n",
      "Requirement already satisfied: packaging>=22.0.0 in /opt/conda/lib/python3.10/site-packages (from pandas-gbq) (24.2)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core<3.0.0dev,>=2.10.2->pandas-gbq) (1.69.2)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /opt/conda/lib/python3.10/site-packages (from google-api-core<3.0.0dev,>=2.10.2->pandas-gbq) (3.20.3)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /opt/conda/lib/python3.10/site-packages (from google-api-core<3.0.0dev,>=2.10.2->pandas-gbq) (1.26.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /opt/conda/lib/python3.10/site-packages (from google-api-core<3.0.0dev,>=2.10.2->pandas-gbq) (2.32.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth>=2.13.0->pandas-gbq) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth>=2.13.0->pandas-gbq) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth>=2.13.0->pandas-gbq) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib>=0.7.0->pandas-gbq) (2.0.0)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery<4.0.0dev,>=3.4.2->pandas-gbq) (2.4.3)\n",
      "Requirement already satisfied: google-resumable-media<3.0.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery<4.0.0dev,>=3.4.2->pandas-gbq) (2.7.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery<4.0.0dev,>=3.4.2->pandas-gbq) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->pandas-gbq) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->pandas-gbq) (2025.2)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery<4.0.0dev,>=3.4.2->pandas-gbq) (1.71.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery<4.0.0dev,>=3.4.2->pandas-gbq) (1.49.0rc1)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.10/site-packages (from google-resumable-media<3.0.0,>=2.0.0->google-cloud-bigquery<4.0.0dev,>=3.4.2->pandas-gbq) (1.7.1)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.13.0->pandas-gbq) (0.6.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.8.2->google-cloud-bigquery<4.0.0dev,>=3.4.2->pandas-gbq) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core<3.0.0dev,>=2.10.2->pandas-gbq) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core<3.0.0dev,>=2.10.2->pandas-gbq) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core<3.0.0dev,>=2.10.2->pandas-gbq) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core<3.0.0dev,>=2.10.2->pandas-gbq) (2025.1.31)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.7.0->pandas-gbq) (3.2.2)\n",
      "Collecting sqlalchemy-bigquery\n",
      "  Downloading sqlalchemy_bigquery-1.14.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy-bigquery) (2.24.2)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=1.25.0 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy-bigquery) (2.38.0)\n",
      "Requirement already satisfied: google-cloud-bigquery<4.0.0,>=3.3.6 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy-bigquery) (3.31.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from sqlalchemy-bigquery) (24.2)\n",
      "Requirement already satisfied: sqlalchemy<3.0.0,>=1.4.16 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy-bigquery) (2.0.40)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->sqlalchemy-bigquery) (1.69.2)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->sqlalchemy-bigquery) (3.20.3)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->sqlalchemy-bigquery) (1.26.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->sqlalchemy-bigquery) (2.32.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0,>=1.25.0->sqlalchemy-bigquery) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0,>=1.25.0->sqlalchemy-bigquery) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0,>=1.25.0->sqlalchemy-bigquery) (4.9)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery<4.0.0,>=3.3.6->sqlalchemy-bigquery) (2.4.3)\n",
      "Requirement already satisfied: google-resumable-media<3.0.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery<4.0.0,>=3.3.6->sqlalchemy-bigquery) (2.7.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery<4.0.0,>=3.3.6->sqlalchemy-bigquery) (2.9.0.post0)\n",
      "Requirement already satisfied: greenlet>=1 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy<3.0.0,>=1.4.16->sqlalchemy-bigquery) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy<3.0.0,>=1.4.16->sqlalchemy-bigquery) (4.13.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery<4.0.0,>=3.3.6->sqlalchemy-bigquery) (1.71.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery<4.0.0,>=3.3.6->sqlalchemy-bigquery) (1.49.0rc1)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.10/site-packages (from google-resumable-media<3.0.0,>=2.0.0->google-cloud-bigquery<4.0.0,>=3.3.6->sqlalchemy-bigquery) (1.7.1)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=1.25.0->sqlalchemy-bigquery) (0.6.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.8.2->google-cloud-bigquery<4.0.0,>=3.3.6->sqlalchemy-bigquery) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->sqlalchemy-bigquery) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->sqlalchemy-bigquery) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->sqlalchemy-bigquery) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->sqlalchemy-bigquery) (2025.1.31)\n",
      "Downloading sqlalchemy_bigquery-1.14.0-py3-none-any.whl (40 kB)\n",
      "Installing collected packages: sqlalchemy-bigquery\n",
      "Successfully installed sqlalchemy-bigquery-1.14.0\n"
     ]
    }
   ],
   "source": [
    "!pip install google-cloud-bigquery\n",
    "!pip install gcloud\n",
    "!pip install langchain\n",
    "!pip install -U langchain-community\n",
    "!pip install -qU langchain_google_vertexai\n",
    "!pip install pandas-gbq\n",
    "!pip install sqlalchemy-bigquery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e22773-9a03-47de-9b6d-7946abcba722",
   "metadata": {},
   "source": [
    "Set your project id, location, and bucket variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7193a9ac-3169-45c1-9c5d-ba5e2f31458f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "project_id='cit-cl-odss-ramsivakumar-df75'\n",
    "location='us-east4'\n",
    "bucket = 'big-query-test-rs'\n",
    "dataset_name = 'big_query_dataset_rs'\n",
    "table_name = \"test-table\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0d9eda-ee54-4c4c-86e6-9166b2b82e2d",
   "metadata": {},
   "source": [
    "Create a bucket where the data used for tutorial is going to be placed. It is important to keep in mind that the name of the bucket has to be unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b583234-2d92-4e5b-841d-c7d79dd87d45",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://big-query-test-rs/...\n"
     ]
    }
   ],
   "source": [
    "# make bucket\n",
    "!gsutil mb -l {location} gs://{bucket}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5781a07c-84ed-416c-a782-b1dc881e5c18",
   "metadata": {},
   "source": [
    "Once the bucket is created, we need to access the CSV source file. In this tutorial, we transferred the data file to our Jupyter notebook by simply dragging and dropping it from my local folder. Next, we need to specify the bucket name and the path of the data source in order to upload the CSV file to the bucket. \n",
    "\n",
    "We are using the [Data Science Salaries](https://www.kaggle.com/datasets/ajjarvis/ds-salaries) dataset from kaggle for this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4829094e-61a6-4dd7-854f-6b21dc19b1b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://health_screening_data.csv [Content-Type=text/csv]...\n",
      "- [1 files][  4.8 MiB/  4.8 MiB]                                                \n",
      "Operation completed over 1 objects/4.8 MiB.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp 'ds_salaries.csv' gs://{bucket}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb53613-326d-4608-8c55-cf9bef115d88",
   "metadata": {},
   "source": [
    "### Create a database in BigQuery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a00dc83-8713-4ea5-9345-08a9f3d785d0",
   "metadata": {},
   "source": [
    "The next step is to create a database in BigQuery. To accomplish this, we need to define a dataset_id and construct a dataset object that will be sent to the API for creation. Note that in BigQuery, a dataset is analogous to a database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1750e13d-ec05-4335-82a2-ffe54c5b5f32",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dataset cit-cl-odss-ramsivakumar-df75.big_query_dataset_rs\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Set dataset_id to the ID of the dataset to create.\n",
    "dataset_id = f'{project_id}.{dataset_name}'\n",
    "\n",
    "# Construct a full Dataset object to send to the API.\n",
    "dataset = bigquery.Dataset(dataset_id)\n",
    "\n",
    "# Specify the geographic location where the dataset should reside.\n",
    "dataset.location = location\n",
    "\n",
    "# Send the dataset to the API for creation, with an explicit timeout.\n",
    "# Raises google.api_core.exceptions.Conflict if the Dataset already\n",
    "# exists within the project.\n",
    "dataset = client.create_dataset(dataset, timeout=30)  # Make an API request.\n",
    "print(\"Created dataset {}.{}\".format(client.project, dataset.dataset_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a1499e-0439-48ab-8042-cc7b8625efd8",
   "metadata": {},
   "source": [
    "Now you have two options to create your table (please pick one):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b421e99e-e493-42b0-9bba-5ffa9d9f1f7b",
   "metadata": {},
   "source": [
    "#### Option 1: Auto detect "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e18540d-defa-414b-8b78-b86bce3dd46a",
   "metadata": {},
   "source": [
    "The following code will auto detect the table schema and upload the data to the table in one step!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "671aa2a3-d259-42e3-8cc3-8ab6b1e4a7d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 69960 rows.\n"
     ]
    }
   ],
   "source": [
    "table_id = f'{dataset_id}.{table_name}'\n",
    "\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    autodetect=True, source_format=bigquery.SourceFormat.CSV, skip_leading_rows=1,\n",
    ")\n",
    "uri = f\"gs://{bucket}/ds_salaries.csv\"\n",
    "load_job = client.load_table_from_uri(\n",
    "    uri, table_id, job_config=job_config\n",
    ")  # Make an API request.\n",
    "load_job.result()  # Waits for the job to complete.\n",
    "destination_table = client.get_table(table_id)\n",
    "print(\"Loaded {} rows.\".format(destination_table.num_rows))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf413f17-c0ab-4d4a-b333-94b05d0bd376",
   "metadata": {},
   "source": [
    "#### Option 2: Manually create schema and upload CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544c191c-2bc0-4a47-a0a7-cea81035597a",
   "metadata": {},
   "source": [
    "Alternatively, if we choose to define the table schema and create the dataset table beforehand, we can use the following code. Afterward, we can upload the CSV dataset into a pandas DataFrame and then insert it into the newly created BigQuery table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68206b14-1b5e-49c3-9f07-52ba6c70a93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set table_id to the ID of the table to create.\n",
    "\n",
    "client = bigquery.Client()\n",
    "\n",
    "table_id = f'{project_id}.{dataset_name}.{table_name}'\n",
    "\n",
    "schema = [\n",
    "    bigquery.SchemaField(\"id\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"age\", \"INTEGER\", mode=\"NULLABLE\"),    \n",
    "    bigquery.SchemaField(\"gender\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"height\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"weight\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"ap_hi\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"ap_lo\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"cholesterol\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"gluc\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"smoke\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"alco\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"active\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"cardio\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"ageinyr\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"bmi\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"bmicat\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"agegroup\", \"STRING\", mode=\"NULLABLE\"),\n",
    "\n",
    "]\n",
    "\n",
    "table = bigquery.Table(table_id, schema=schema)\n",
    "table = client.create_table(table)  # Make an API request.\n",
    "print(\n",
    "    \"Created table {}.{}.{}\".format(table.project, table.dataset_id, table.table_id)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c87a0f1-de43-4cce-a5e2-8952ce2283a0",
   "metadata": {},
   "source": [
    "We load our dataset located in our bucket to a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2486d4e3-b462-42de-85ab-3c6d5a8ba363",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "path = \"<gsutil URI>\"\n",
    "df = pd.read_csv(path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dad23f6-cc3f-4bc6-b5ff-a66d17740a65",
   "metadata": {},
   "source": [
    "We need to use the \"to_gbq\" function from the pandas-gbq library, which allows us to write a Pandas DataFrame to a Google BigQuery table. This enables us to populate our BigQuery table with the data from the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfd1d66-a0fb-403d-a9b1-27250cc81f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_gbq(table_id, project_id=project_id)\n",
    "\n",
    "client.load_table_from_dataframe(df, table_id).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e97b4c6-429c-4d36-a4c1-3963b079af6a",
   "metadata": {},
   "source": [
    "This step is optional. We can make an API request to verify whether the dataset has been successfully created under our project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f11cfd-8b20-48bf-b157-aaf791cd3a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = list(client.list_datasets())  # Make an API request.\n",
    "project = project_id\n",
    "\n",
    "if datasets:\n",
    "    print(\"Datasets in project {}:\".format(project))\n",
    "    for dataset in datasets:\n",
    "        print(\"\\t{}\".format(dataset.dataset_id))\n",
    "else:\n",
    "    print(\"{} project does not contain any datasets.\".format(project))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b16a292-afdc-415c-a8a7-071bc90281c3",
   "metadata": {},
   "source": [
    "![image.png](../../images/gcp_rag_structure_data_01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9014cb-2226-4168-b96e-d01021bee230",
   "metadata": {},
   "source": [
    "### Optional: Run a query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b4dd65-9bd9-48ef-9c98-85e3e9a82701",
   "metadata": {},
   "source": [
    "This step is also optional. We can execute a simple query on the BigQuery table to count the number of records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29e91fc1-735f-4d6c-9fcf-3a2d745363c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "BadRequest",
     "evalue": "400 Syntax error: Unexpected string literal 'project_id.dataset_id.table_id' at [3:10]; reason: invalidQuery, location: query, message: Syntax error: Unexpected string literal 'project_id.dataset_id.table_id' at [3:10]\n\nLocation: US\nJob ID: d46a901a-4a22-4bb6-b499-0e32e78fc550\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequest\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m query_job \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mquery(query)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Fetch the results\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mquery_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Iterate through the rows\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m results:\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m#print(f\"gender: {row.name}, age: {row.age}\")\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/job/query.py:1681\u001b[0m, in \u001b[0;36mQueryJob.result\u001b[0;34m(self, page_size, max_results, retry, timeout, start_index, job_retry)\u001b[0m\n\u001b[1;32m   1676\u001b[0m     remaining_timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1679\u001b[0m     \u001b[38;5;66;03m# Since is_job_done() calls jobs.getQueryResults, which is a\u001b[39;00m\n\u001b[1;32m   1680\u001b[0m     \u001b[38;5;66;03m# long-running API, don't delay the next request at all.\u001b[39;00m\n\u001b[0;32m-> 1681\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mis_job_done\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1682\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1683\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1684\u001b[0m     \u001b[38;5;66;03m# Use a monotonic clock since we don't actually care about\u001b[39;00m\n\u001b[1;32m   1685\u001b[0m     \u001b[38;5;66;03m# daylight savings or similar, just the elapsed time.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    292\u001b[0m )\n\u001b[0;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:153\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43msleep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(sleep)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/retry/retry_base.py:212\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[1;32m    207\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[1;32m    208\u001b[0m         error_list,\n\u001b[1;32m    209\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[1;32m    210\u001b[0m         original_timeout,\n\u001b[1;32m    211\u001b[0m     )\n\u001b[0;32m--> 212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m     on_error_fn(exc)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[1;32m    146\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/job/query.py:1630\u001b[0m, in \u001b[0;36mQueryJob.result.<locals>.is_job_done\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m job_failed_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1608\u001b[0m     \u001b[38;5;66;03m# Only try to restart the query job if the job failed for\u001b[39;00m\n\u001b[1;32m   1609\u001b[0m     \u001b[38;5;66;03m# a retriable reason. For example, don't restart the query\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1627\u001b[0m     \u001b[38;5;66;03m# into an exception that can be processed by the\u001b[39;00m\n\u001b[1;32m   1628\u001b[0m     \u001b[38;5;66;03m# `job_retry` predicate.\u001b[39;00m\n\u001b[1;32m   1629\u001b[0m     restart_query_job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m-> 1630\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m job_failed_exception\n\u001b[1;32m   1631\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1632\u001b[0m     \u001b[38;5;66;03m# Make sure that the _query_results are cached so we\u001b[39;00m\n\u001b[1;32m   1633\u001b[0m     \u001b[38;5;66;03m# can return a complete RowIterator.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1639\u001b[0m     \u001b[38;5;66;03m# making any extra API calls if the previous loop\u001b[39;00m\n\u001b[1;32m   1640\u001b[0m     \u001b[38;5;66;03m# iteration fetched the finished job.\u001b[39;00m\n\u001b[1;32m   1641\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reload_query_results(\n\u001b[1;32m   1642\u001b[0m         retry\u001b[38;5;241m=\u001b[39mretry, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mreload_query_results_kwargs\n\u001b[1;32m   1643\u001b[0m     )\n",
      "\u001b[0;31mBadRequest\u001b[0m: 400 Syntax error: Unexpected string literal 'project_id.dataset_id.table_id' at [3:10]; reason: invalidQuery, location: query, message: Syntax error: Unexpected string literal 'project_id.dataset_id.table_id' at [3:10]\n\nLocation: US\nJob ID: d46a901a-4a22-4bb6-b499-0e32e78fc550\n"
     ]
    }
   ],
   "source": [
    "query = f\"\"\"\n",
    "    SELECT count(gender) as cgender\n",
    "    FROM '{project_id.dataset_id.table_id}'\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query\n",
    "query_job = client.query(query)\n",
    "\n",
    "# Fetch the results\n",
    "results = query_job.result()\n",
    "\n",
    "# Iterate through the rows\n",
    "for row in results:\n",
    "    #print(f\"gender: {row.name}, age: {row.age}\")\n",
    "    print(f\"cgender: {row.cgender}\")\n",
    "\n",
    "try:\n",
    "    query_job = client.query(query)\n",
    "    results = query_job.result()\n",
    "    print(results)\n",
    "except Exception as e:\n",
    "    print(f\"Error executing query: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce65ead3-694d-4d46-9376-38d35b8d0852",
   "metadata": {},
   "source": [
    "cgender: 139920\n",
    "<google.cloud.bigquery.table.RowIterator object at 0x7f226b88ab90>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cd8a0d-9845-4d84-abf6-2610ed946b7e",
   "metadata": {},
   "source": [
    "### Connect our model and Big Query database and run a query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fb53b8-9f93-4f37-8730-33c5871720fc",
   "metadata": {},
   "source": [
    "To interact with the BigQuery table using a Pythonic domain language, we utilize SQLAlchemy. SQLAlchemy is a Python SQL toolkit that enables developers to access and manage SQL databases, allowing users to write queries as strings or chain Python objects for similar queries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1d29b90-7bcd-46b8-82b9-dc5e58f9edee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigquery://cit-cl-odss-ramsivakumar-df75/big_query_dataset_rs\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "from sqlalchemy import *\n",
    "from sqlalchemy.engine import create_engine\n",
    "from sqlalchemy.schema import *\n",
    "import os\n",
    "from langchain_community.agent_toolkits import create_sql_agent\n",
    "from langchain.agents import create_sql_agent\n",
    "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain.sql_database import SQLDatabase\n",
    "\n",
    "sqlalchemy_url = f'bigquery://{project_id}/{dataset_name}'\n",
    "print(sqlalchemy_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9194cc1d-7ef1-4c4e-8e65-e7d9ada5be24",
   "metadata": {},
   "source": [
    "Next, we import the __ChatVertexAI__ agent from Langchain and configure it with the appropriate hyperparameters. In this instance, we are using the __gemini-1.5-pro__ LLM model, after which we create the SQL agent to enable querying the BigQuery table using a natural language string as a prompt. Temperature regulates randomness, with higher temperatures resulting in more varied and unpredictable outputs. Top-k sampling selects from the k most probable next tokens at each step, where a lower k emphasizes higher-probability tokens. The max tokens hyperparameter specifies the maximum number of tokens in the response from the large language model. Max retries indicates how many responses we will receive from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee1899a2-dd79-4cf4-a02d-c7c35b99040b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_google_vertexai import VertexAI, ChatVertexAI\n",
    "\n",
    "llm = ChatVertexAI(\n",
    "    model=\"gemini-1.5-pro\",\n",
    "    temperature=0,\n",
    "    max_tokens=8190,\n",
    "    max_retries=2,\n",
    ")\n",
    "db = SQLDatabase.from_uri(sqlalchemy_url)\n",
    "toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
    "agent_executor = create_sql_agent(\n",
    "    llm=llm,\n",
    "    toolkit=toolkit,\n",
    "    verbose=True,\n",
    "    top_k=100000\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3551426-8644-48ba-b8c1-bf7d5eb843b3",
   "metadata": {},
   "source": [
    "For our initial query, we check the number of rows to compare the result with what we obtained in a previous step using a simple SQL query against the BigQuery table. We can confirm that we received the same number of rows: 139,920."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9753533-e82b-47af-936a-a401d512308a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_10383/3618013291.py:1: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  agent_executor.run(\"How many rows are in the table screening? \")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SQL Agent Executor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I should look at the tables in the database to see what I can query.  Then I should query the schema of the most relevant tables.\n",
      "Action: sql_db_list_tables\n",
      "Action Input: \u001b[0m\u001b[38;5;200m\u001b[1;3mtest-table\u001b[0m\u001b[32;1m\u001b[1;3mAction: sql_db_schema\n",
      "Action Input: test-table\u001b[0m\u001b[33;1m\u001b[1;3m\n",
      "CREATE TABLE `test-table` (\n",
      "\t`int64_field_0` INT64, \n",
      "\t`id` INT64, \n",
      "\t`age` INT64, \n",
      "\t`gender` INT64, \n",
      "\t`height` INT64, \n",
      "\t`weight` FLOAT64, \n",
      "\t`ap_hi` INT64, \n",
      "\t`ap_lo` INT64, \n",
      "\t`cholesterol` INT64, \n",
      "\t`gluc` INT64, \n",
      "\t`smoke` INT64, \n",
      "\t`alco` INT64, \n",
      "\t`active` INT64, \n",
      "\t`cardio` INT64, \n",
      "\t`AgeinYr` INT64, \n",
      "\t`BMI` FLOAT64, \n",
      "\t`BMICat` STRING, \n",
      "\t`AgeGroup` STRING\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from test-table table:\n",
      "int64_field_0\tid\tage\tgender\theight\tweight\tap_hi\tap_lo\tcholesterol\tgluc\tsmoke\talco\tactive\tcardio\tAgeinYr\tBMI\tBMICat\tAgeGroup\n",
      "33817\t48318\t21582\t2\t178\t11.0\t130\t90\t1\t1\t0\t0\t1\t1\t59\t3.5\tUnder Weight\t40-60\n",
      "57858\t82567\t18804\t2\t165\t10.0\t180\t1100\t2\t2\t0\t0\t1\t1\t51\t3.7\tUnder Weight\t40-60\n",
      "29488\t42156\t20408\t2\t177\t22.0\t120\t80\t1\t1\t1\t1\t1\t0\t55\t7.0\tUnder Weight\t40-60\n",
      "*/\u001b[0m\u001b[32;1m\u001b[1;3mI can query the table `test-table` to find out how many rows it has.\n",
      "Action: sql_db_query_checker\n",
      "Action Input: SELECT COUNT(*) FROM `test-table`\u001b[0m\u001b[36;1m\u001b[1;3mSELECT COUNT(*) FROM `test-table`\n",
      "\u001b[0m\u001b[32;1m\u001b[1;3mAction: sql_db_query\n",
      "Action Input: SELECT COUNT(*) FROM `test-table`\u001b[0m\u001b[36;1m\u001b[1;3m[(69960,)]\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: The table test-table has 69960 rows.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The table test-table has 69960 rows.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.run(\"How many rows are in the table screening? \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b62012-b2d2-48c1-ae69-6f8816065551",
   "metadata": {},
   "source": [
    "Next, we pose a question that requires applying a filter, and we successfully obtain the accurate number of obese individuals in the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5563d317-81ab-4a37-8225-e1b0dce20b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.run(\"How many obese are in the table screen?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96ea414-3f2d-4e66-ab0b-a034dfe507b0",
   "metadata": {},
   "source": [
    "As a more complex query, we inquired about the number of female smokers, and the SQL agent accurately returned the answer of 1,626 female smokers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a456ff90-a3a5-4ee4-81da-fba4fcdf7f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.run(\"How many smokers are female in the table screen? the value 1 in smoke means that is a smoker and the value 2 in gender means that is a female\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0fb657-19e0-4488-b9f6-25ca3971064f",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f85e560-231f-4841-b1d0-334326e4b347",
   "metadata": {},
   "source": [
    "You have learned how to create a dataset and a table in BigQuery, as well as how to set up an agent that enables you to query the table using natural language instead of SQL queries, allowing you to obtain the results you need."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41573388-7feb-44b6-9e8a-0511cc8ae62e",
   "metadata": {},
   "source": [
    "## Clean Up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0edc0b-f2cc-478c-855f-9acff3792f4d",
   "metadata": {},
   "source": [
    "Please remember to delete or stop your Jupyter notebook and delete your BigQuery dataset and table to prevent incurring charges. And if you have created any other services like buckets, please remember to delete them as well."
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m129",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m129"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

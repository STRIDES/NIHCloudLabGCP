{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c51ed24c-53dd-4239-8be0-0e0422596ba3",
   "metadata": {},
   "source": [
    "# Intro to GCP's Gemini "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cc412f-5338-45ba-8b29-9039c19208d9",
   "metadata": {},
   "source": [
    "**Gemini** is a Google multimodal model that has the capability to **summarize, chat, and generate text from images or videos**. Gemini comes in two model versions **Gemini Pro** and **Gemini Pro Vision**, for this tutorial we will be looking into utilizing both models via python packages and GCPs model playground, **Vertex AI Studio**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "+ Learn how to interact with Gemini as a chatbot from a Jupyter notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "+ You need access to Vertex AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ec6d40-b5b3-434f-adc4-2838b7f49d1d",
   "metadata": {
    "tags": []
   },
   "source": [
    "Update the google-cloud-aiplatform package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9781dd-9764-4e9c-88ba-fcd7bb95842a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip install --upgrade google-cloud-aiplatform  langchain langchain-community"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bbbed7-becf-48d0-98c3-6dd9942fd377",
   "metadata": {},
   "source": [
    "Next we initialize the Gemini model by setting out project id and location. We are also pulling in the packages:\n",
    "- **GenerativeModel:** Allows us to specify and launch the Gemini model we need (e.g. Gemini Pro, Gemini Pro Vision).\n",
    "- **ChatSession:** Set Gemini Pro in chatbot mode.\n",
    "- **Part:** Loads in files from buckets.\n",
    "- **Image:** Loads in image files locally.\n",
    "- **GenerationConfig:** Allows us to configure the models temperature, top p, top k, and max tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47dc9232-383f-405b-b1a8-fab64a80492d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel, Image, GenerativeModel, ChatSession, Part, GenerationConfig\n",
    "\n",
    "# TODO(developer): Update and un-comment below lines\n",
    "project_id = \"<PROJECT_ID>\"\n",
    "location = \"<LOCATION>\" #(e.g., us-central1)\n",
    "vertexai.init(project=project_id, location=location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Started"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022f24ba-4034-4424-91d8-1229682755ab",
   "metadata": {},
   "source": [
    "### Gemini as a Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7dec028-6d30-4078-ac54-62b849ae9ced",
   "metadata": {},
   "source": [
    "For dealing with text, code generation, natural language tasks we can use the **gemini-pro** model and to set our model in **chatbot mode** we need to use the `start_chat()` function. You will see below we also created a function named **get_chat_response** which will send the prompt or message we have for our model using the `send_message()` function and returns only the text of the chats response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bc5b25-c796-4015-82dc-6bc861bb525f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = GenerativeModel(\"gemini-pro\")\n",
    "chat = model.start_chat()\n",
    "\n",
    "def get_chat_response(chat: ChatSession, prompt: str):\n",
    "    response = chat.send_message(prompt)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae40e87a-76ac-469b-a504-fb903319cbaf",
   "metadata": {},
   "source": [
    "Now that we have our functions lets ask our Gemini chatbot some questions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3277de-ab85-417f-b1d8-b21985a7a21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Hello.\"\n",
    "print(get_chat_response(chat, prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342a0e3d-fbcb-4562-bb5f-b439a92e80e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"List gen ai use cases that are Life Science or Health Care related. \"\n",
    "print(get_chat_response(chat, prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfda59a-c440-4489-8f00-a4316b827292",
   "metadata": {},
   "source": [
    "We can even ask it to **generate code or debug code**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b917b2-22b5-4011-a9c4-d8a667cf6b1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"create a python code that will replace all null values to zero within a csv file\"\n",
    "print(get_chat_response(chat, prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9d57d2-dbe1-434a-9345-fe5ae3315a21",
   "metadata": {},
   "source": [
    "### Gemini as a Summarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4856bd61-3e24-40ea-8da4-1a6edc5f3e1d",
   "metadata": {},
   "source": [
    "We can generate text like asking Gemini Pro to summarize articles we provide locally (using langchain). As of now Gemini does not support loading in documents that are not videos and images directly. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d7df19-a625-40dc-b4e5-faff5e7ba241",
   "metadata": {},
   "source": [
    "First we will load in a file using langchains text loader. You can also use langchain to load in files from your bucket following the instructions [here](https://python.langchain.com/docs/integrations/document_loaders/google_cloud_storage_file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4cf184-c815-425c-9742-7625123e02bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#download the article\n",
    "!wget --user-agent \"Chrome\" https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10954554/pdf/41586_2024_Article_7159.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3becd6c2-daf0-4287-80e5-06cf419287bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"41586_2024_Article_7159.pdf\")\n",
    "ex_file=loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3d6c19-7d68-49e1-85e9-91bcd6bd1775",
   "metadata": {},
   "source": [
    "We can configure our model to give us the best optimal output by setting the parameters below:\n",
    "- **Max_Output_Token**: Max number of words to generate.\n",
    "- **Temperature:** Controls randomness, higher values increase diversity meaning a more unique response make the model to think harder. Must be a number from 0 to 1.\n",
    "- **Top_p (nucleus):** The cumulative probability cutoff for token selection. Lower values mean sampling from a smaller, more top-weighted nucleus. Must be a number from 0 to 1.\n",
    "- **Top_k:** Sample from the k most likely next tokens at each step. Lower k focuses on higher probability tokens. This means the model choses the most probable words. Lower values eliminate fewer coherent words.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4228e44-9639-40da-8f69-343be93b65b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_config = GenerationConfig(\n",
    "    temperature=0.9,\n",
    "    top_p=1.0,\n",
    "    top_k=32,\n",
    "    candidate_count=1,\n",
    "    max_output_tokens=8192,\n",
    ")\n",
    "\n",
    "def summarizer(file: str) -> str:\n",
    "        \n",
    "    # Query the model\n",
    "    response = model.generate_content(\n",
    "        [\n",
    "            # Add an example query\n",
    "            \"summarize this file.\",\n",
    "            file\n",
    "        ],\n",
    "        generation_config=generation_config,\n",
    "    )\n",
    "    #print(response)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb722d6-ef79-4a0b-9327-04811e7f8ffc",
   "metadata": {},
   "source": [
    "Here we are inputting only the page content from our document loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e7ea82-c58e-42ee-b01e-6aa51e324b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(summarizer(ex_file[0].page_content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c10bd8-1570-4dfa-9b2a-999e3f149faf",
   "metadata": {},
   "source": [
    "### Gemini as a Image to Text Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476052b3-ff64-4e5a-819c-7a18daf7f413",
   "metadata": {},
   "source": [
    "Gemini Pro Vision can generate text from images and videos. These text can be descriptions or questions about the image or video. You can download an image or retrieve an image from your bucket or locally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214ee84f-f058-411a-944d-4e149cd0e9bc",
   "metadata": {},
   "source": [
    "Images can only be in the following formats: \n",
    "- PNG - image/png\n",
    "- JPEG - image/jpeg\n",
    "\n",
    "Our function below takes in a prompt and the image, we have also included a if statement to recognize if the function should use `Image` to load in a image locally or `Part` to load it from a bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501efefe-d52f-43b3-b4eb-3d3fe81f4a3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def img2text(image_path: str, img_prompt: str) -> str:\n",
    "    multimodal_model = GenerativeModel(\"gemini-pro-vision\")\n",
    "    if \"gs://\" in image_path:\n",
    "        image1=Part.from_uri(image_path, mime_type=\"image/jpeg\")\n",
    "    else: \n",
    "        image1=Image.load_from_file(image_path)\n",
    "        \n",
    "    responses = multimodal_model.generate_content(\n",
    "        [image1, img_prompt],\n",
    "        generation_config={\n",
    "            \"max_output_tokens\": 2048,\n",
    "            \"temperature\": 0.4,\n",
    "            \"top_p\": 1,\n",
    "            \"top_k\": 32\n",
    "        },\n",
    "        stream=True,\n",
    "    )\n",
    "    for response in responses:\n",
    "        print(response.text, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cafaaa8-f3c7-472a-8f0b-6595d2112636",
   "metadata": {},
   "source": [
    "Lets look at an image locally, by loading a image first, this a image of a Covid virus from the [CDC Public Health Image Library](https://phil.cdc.gov/details.aspx?pid=23312)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b939f105-89c2-4c38-80f8-2cddf8dcb0ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! wget -O example_image_covid.jpg \"https://phil.cdc.gov//PHIL_Images/23312/23312_lores.jpg\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696d9fc7-0ca9-44a7-b431-a9698b1a636c",
   "metadata": {},
   "source": [
    "Now run our function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e81656-4943-439d-9fbe-df439e0e30df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(img2text(\"example_image_covid.jpg\", \"describe this image.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc152659-7bc4-46bc-9ead-4736b4ad2706",
   "metadata": {},
   "source": [
    "Next we'll look at an image from a bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81197d53-dd3d-4358-9835-ef513ec11d33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(img2text(\"gs://generativeai-downloads/images/scones.jpg\", \"describe this image.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e3c48f-66e9-40e1-8623-04f73b672507",
   "metadata": {},
   "source": [
    "We can even ask for more details related to the items in our image!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8395784-ea68-4a95-a0bb-b3d618f68054",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_prompt=\"How do you make whats in this image?\"\n",
    "image=\"gs://generativeai-downloads/images/scones.jpg\"\n",
    "print(img2text(image, img_prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960f7ba6-8236-437a-ba99-ea1d887efd64",
   "metadata": {},
   "source": [
    "### Gemini as a Video to Text Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdbbd35-f36f-4467-8a1d-48ccd942d7cc",
   "metadata": {},
   "source": [
    "Just like images we will be using the same model Gemini Pro Vision. We can load videos locally and from a bucket just like images. Video files can only be in the following formats:\n",
    "- MOV - video/mov\n",
    "- MPEG - video/mpeg\n",
    "- MP4 - video/mp4\n",
    "- MPG - video/mpg\n",
    "- AVI - video/avi\n",
    "- WMV - video/wmv\n",
    "- MPEGPS - video/mpegps\n",
    "- FLS - video/flv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f94141-b5ba-49bf-a3d7-d0b68ccdd39a",
   "metadata": {},
   "source": [
    "Our function below takes a video from a public bucket and asks for a prompt and the location of the video file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18561c6-8f8f-46e4-b3ee-0d5fc96f2d31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def video2text(video_path: str, video_prompt: str) -> str:\n",
    "    # Query the model\n",
    "    multimodal_model = GenerativeModel(\"gemini-pro-vision\")\n",
    "    response = multimodal_model.generate_content(\n",
    "        [\n",
    "            # Add an example image\n",
    "            Part.from_uri(\n",
    "                video_path, mime_type=\"video/mp4\"\n",
    "            ),\n",
    "            # Add an example query\n",
    "            video_prompt,\n",
    "        ],\n",
    "        stream=True\n",
    "    )\n",
    "    for chunk in response :\n",
    "        return print(chunk.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492f9100-b5a4-446c-a03d-dd89a1b4bbde",
   "metadata": {},
   "source": [
    "Run the function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55990074-0365-45f5-9fa6-bedbe93c9932",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "video_prompt = \"What is this video about in detail?\"\n",
    "video = \"gs://cloud-samples-data/video/Machine Learning Solving Problems Big, Small, and Prickly.mp4\"\n",
    "print(video2text(video, video_prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32253b4-d892-4c0c-896e-320c8df479c7",
   "metadata": {},
   "source": [
    "## Gemini on Vertex AI Studio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614883f2-e53a-4ba5-855c-209d755a6e6f",
   "metadata": {},
   "source": [
    "You can also use Gemini Pro and Pro Vision in Vertex AI's playground called **Vertex AI Studio**. To locate Vertex AI Studio search Vertex AI and on the left hand side locate Vertex AI Studio as the image below shows. To utilize Gemini Pro Vision locate and click **Multimodal** you will have the option to use your own prompt or explore some of the other set prompts such as Extract text from images, image question answering , etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a634e11-3bd5-4048-b6e4-46d5aac6ce34",
   "metadata": {},
   "source": [
    "![Gemini1](../../images/Gemini_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3716d9d-49af-40c9-acce-757c53be9a12",
   "metadata": {},
   "source": [
    "For this tutorial we will select Open on the **Prompt Design** option. We will upload the COVID image we downloaded before by clicking **INSERT MEDIA** and selecting our file. Then we will ask it a question, here we asked \"Describe treatments for the item in this image\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec72f9cd-0d06-47e4-b67c-45039372d967",
   "metadata": {
    "tags": []
   },
   "source": [
    "![Gemini3](../../images/Gemini_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a88f06b-770a-43be-b875-b4054c3ccbf3",
   "metadata": {},
   "source": [
    "To utilize Gemini Pro locate and click **Language** on the left side menu. You have the option to use a prompt or chat and if you would like to focus on text or code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1952cd5c-c93d-428f-8036-ac658eebfba4",
   "metadata": {
    "tags": []
   },
   "source": [
    "![Gemini2](../../images/Gemini_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7810c0db-d145-4acd-a2cc-b6ce8231fa14",
   "metadata": {},
   "source": [
    "Here we picked the **TEXT CHAT** option and asked the bot to describe covid and how it works."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b4635d-d8f3-42df-959d-dff92259813c",
   "metadata": {
    "tags": []
   },
   "source": [
    "![Gemini4](../../images/Gemini_4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc53b99-e6ed-45f1-a0e1-9b146e18e46c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m119",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m119"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

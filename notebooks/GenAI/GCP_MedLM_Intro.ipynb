{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fa120da-a0b4-4d1d-bc53-66639dfca134",
   "metadata": {},
   "source": [
    "# Intro to Google Cloud's MedLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d156f0b-cee6-4b7c-bb0c-314c1491e076",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c698b367-c306-4f1d-a457-81fb3dea3d32",
   "metadata": {},
   "source": [
    "MedLM is a large language model developed by Google AI and is specifically designed for medical applications.\n",
    "this model was trained on a massive dataset of medical text and code, including research papers, clinical notes, and medical textbooks. This allows it to understand and generate text related to medical concepts, diseases, treatments, and procedures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269c66e9-4f8a-4aa5-bc36-426621b63480",
   "metadata": {},
   "source": [
    "## Learning objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d0ce29-0a56-439c-8982-3369cb840797",
   "metadata": {},
   "source": [
    "- Learn how to utilize MedLM via Python and Rest API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa51987-92ea-4a1b-b051-4ddcf3eec31a",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25489cf3-854d-4845-8a05-5baafc9987eb",
   "metadata": {},
   "source": [
    "You must have enabled the Vertex AI and Compute Engine APIs. **NIH users and NIH affiliated** must submit the following form **[here](https://gcc02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fforms.gle%2FDemhsTFKLLSGfPFZ8&data=05%7C02%7Czelaikha.yosufzai%40nih.gov%7C1e2602eb34664b27402c08dc751c7365%7C14b77578977342d58507251ca2dc2b06%7C0%7C0%7C638514012259395224%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0%7C%7C%7C&sdata=7UqyEipLBhZcwkzH%2FQ5B4IwtSEC6jlshLxmhKvaSUQ4%3D&reserved=0)** to gain access to MedLM. All other users should contact their Google support team to gain access."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a048af45-d64d-4abf-a85e-6b2abeb0e97c",
   "metadata": {},
   "source": [
    "## Get started"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e0fa64-8599-46ba-aa4d-0cc171914f37",
   "metadata": {},
   "source": [
    "### MedLM with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4016ad-9f5a-45c6-bf92-484d85d65c5b",
   "metadata": {},
   "source": [
    "To invoke MedLM via python you will first need to import Vertex AI language models package, then enter in your project id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265f5c42-51e2-4dbd-bc42-4d7bf1075bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import vertexai\n",
    "from vertexai.language_models import TextGenerationModel\n",
    "\n",
    "#Entere your Project ID\n",
    "PROJECT_ID = '<PROJECT_ID>'\n",
    "location = \"<Location (e.g.us-central1)>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b6e168-9e44-4ce5-9d5c-3a249253b144",
   "metadata": {},
   "source": [
    "Below we have created a function to invoke our MedLM model which will require a query as the only input. You can also configure the models output via the following variables:\n",
    "\n",
    "- **Max Output Tokens:** Limit of tokens outputted by the model.\n",
    "- **Temperature:** Controls randomness, higher values increase diversity meaning a more unique response make the model to think harder. Must be a number from 0 to 1, 0 being less unique.\n",
    "- **Top_p (nucleus):** The cumulative probability cutoff for token selection. Lower values mean sampling from a smaller, more top-weighted nucleus. Must be a number from 0 to 1.\n",
    "- **Top_k:** Sample from the k most likely next tokens at each step. Lower k focuses on higher probability tokens. This means the model choses the most probable words. Lower values eliminate fewer coherent words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8cc9c8-95a0-4fb5-a84b-b9cbc2d4180f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "vertexai.init(project=PROJECT_ID, location)\n",
    "\n",
    "def medlm_invoke(query):\n",
    "    parameters = {\n",
    "        \"candidate_count\": 1,\n",
    "        \"max_output_tokens\": 256,\n",
    "        \"temperature\": 0.8,\n",
    "        \"top_k\": 40,\n",
    "        \"top_p\": 0.80,\n",
    "    }\n",
    "\n",
    "    model_instance = TextGenerationModel.from_pretrained(\"medlm-medium\")\n",
    "    response = model_instance.predict(\n",
    "        f\"Question: {query}\",\n",
    "        **parameters\n",
    "    )\n",
    "    return f\"Response from Model: {response.text}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c973d661-26aa-4470-b5d3-fa4fe8aed2ef",
   "metadata": {},
   "source": [
    "Lets try out some queries! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d453be-71c8-4ae5-9d29-42d241c0f359",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query1 = 'What causes you to get ringworm?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c74c3f-57c1-43af-89a2-c2b0c055e9b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query2 = 'What is the percentage of covid patients in VA?'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec00be5-471e-4ec2-b98c-d10914434cc0",
   "metadata": {},
   "source": [
    "Enter our query variable into our function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c94766-3f3a-4a96-854e-4d2e8a823032",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "medlm_invoke(query1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b798d2-4286-4a92-a75c-d1d21560dcb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "medlm_invoke(query2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3840913-7ed4-4934-8266-d7da314f3031",
   "metadata": {},
   "source": [
    "### MedLM with REST API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42106c7-fad8-432b-ab56-d86cf5fe1260",
   "metadata": {},
   "source": [
    "Utilizing the REST API is similar to python expect that we will be using curl commands. This will require us to create a **request variable** that specifies the parameters of the model before you can actually invoke or call upon it. As you can see below we have specified our query and the other parameters (temperature, max tokens, top K, and top P)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f1a794-1c37-49b7-b311-fdcbde27f06e",
   "metadata": {},
   "source": [
    "Below you can see we have queries and the structure of our request which will fill in the query and already has our parameters entered. Feel free to change them as you are working with the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62887f8-7400-473c-beee-af120339ac7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'What is the percentage of covid patients in VA?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff52f53a-5435-4542-a82c-0e592d005070",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "request = { \"instances\": \n",
    "           [\n",
    "               {\n",
    "                   \"content\": f\"Question: {query}\"\n",
    "               }\n",
    "           ],\n",
    "           \"parameters\": {\n",
    "               \"temperature\": 0.8,\n",
    "               \"maxOutputTokens\": 256,\n",
    "                \"topK\": 40,\n",
    "                \"topP\": 0.95\n",
    "           }\n",
    "          } "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776ada91-3f93-4d6d-b16d-026066571ccd",
   "metadata": {},
   "source": [
    "Lets take a look at what our request looks like!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6864fb73-7b45-445f-bc94-67f21d1d2ab9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(request)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43983498-bede-4471-9067-81514dafe016",
   "metadata": {},
   "source": [
    "Enter in your project ID and location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585f7dc0-d1d4-495c-8f51-11c7f0687098",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "project_id = \"<Project_ID>\"\n",
    "location = \"<Location(e.g.us-central1)>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597e7203-4250-45fb-8bf0-4a0910f4c52d",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now we can pass our request to our curl command which will invoke the model and send back a response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe62d6fa-360b-4df7-8fe6-3e572acaf2e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!curl -X POST \\\n",
    "    -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
    "    -H \"Content-Type: application/json; charset=utf-8\" \\\n",
    "    -d \"$request\" \\\n",
    "    \"https://us-central1-aiplatform.googleapis.com/v1/projects/$project_id/locations/$location/publishers/google/models/medlm-medium:predict\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed28e06-5459-42b6-8ecf-29665ce1fb73",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e51d748-6520-4180-a823-ba9d940a51be",
   "metadata": {},
   "source": [
    "You have just used the MedLM model and invoked it via python and the REST API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea65b740-1a94-43a8-80e0-4a1a8a446775",
   "metadata": {},
   "source": [
    "## Clean up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5e1533-e7cc-4647-8668-2f06929da1b6",
   "metadata": {},
   "source": [
    "Please remember to delete or stop your **Jupyter notebook** to prevent incurring charges! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1730b237-df81-40ec-8acf-175b45d99f4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m114",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m114"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

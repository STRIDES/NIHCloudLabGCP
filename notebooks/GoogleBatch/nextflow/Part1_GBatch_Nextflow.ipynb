{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5cdaee0-cc9d-430a-8d95-6af15b2534a8",
   "metadata": {},
   "source": [
    "# Use Nextflow to run workflows using the Google Batch Part I"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65493ca",
   "metadata": {},
   "source": [
    "## Overview\n",
    "__What is Google Batch?__ <br>\n",
    "Batch allows you to schedule, queue, and execute batch processing workloads on a VM instances. Batch provisions resources and manages capacity on your behalf, allowing your batch workloads to run at scale. \n",
    "\n",
    "__How does Batch differ from Cloud Life Sciences?__ <br>\n",
    "You don't need to configure and manage third-party job schedulers, provision and deprovision resources, or request resources one zone at a time. To run a job, you specify parameters for the resources required for your workload, then Batch obtains resources and queues the job for execution. Batch provides native integration with other Google Cloud services to aid in the scheduling, execution, storage, and analysis of batch jobs.\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\"> <b>Warning:</b> Google Life Sciences API is depreciated and will no longer be available on GCP by July 8, 2025. </div>\n",
    "\n",
    "Here we are going to walk through submitting simple jobs directly to Google Batch, then dive into interacting with Google Batch using Nextflow. We will run some basic Hello World jobs, then move to a more complex [nf-core Methylseq workflow](https://nf-co.re/methylseq). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aca01d1",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "+ Learn how to use Nextflow in Google Cloud\n",
    "+ Learn how to submit jobs to Google Batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126243b9",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "Make sure that Batch, Compute Engine, and Cloud Storage APIs are all enabled.\n",
    "\n",
    "You also want to make sure your Compute Engine Default Service Account has the following Roles:\n",
    "\n",
    "- Service Account User\n",
    "- Batch Agent Reporter \n",
    "- Storage Admin\n",
    "- Storage Object Admin\n",
    "- Batch Job Editor <br>\n",
    "\n",
    "Your Service Account should already have these roles assigned, but if not, reach out to Support to have your account updated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9b9ca6",
   "metadata": {},
   "source": [
    "## Get Started"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdb7b18",
   "metadata": {},
   "source": [
    "### Install packages and set up environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e4a5ca-8a2b-4156-b83e-c89f0c1ffc9c",
   "metadata": {},
   "source": [
    "### Create a bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c79eb1-6010-4d8a-8725-b92144bab944",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure you change this name, it needs to be globally unique\n",
    "%env BUCKET=gbatch-nextflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d17e57-86e8-4fce-83fe-3c33c7db9dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#will only create the bucket if it doesn't yet exist\n",
    "! gsutil ls gs://$BUCKET >& /dev/null || gsutil mb gs://$BUCKET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553761fd-4ce3-4dda-8319-a10cb9cd5314",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set versioning on the bucket so it can overwrite old files\n",
    "! gsutil versioning set on gs://$BUCKET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d588a5-83b2-42ef-a65f-64b2c80bca3f",
   "metadata": {},
   "source": [
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acefde5-3f8a-42cb-aa12-46396eaae644",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First install java\n",
    "! sudo apt update\n",
    "! sudo apt-get install default-jdk -y\n",
    "! java -version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8538e0-49a3-4e61-abf3-a08e1b397fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify nexflow version and platfrom\n",
    "! export NXF_VER=21.10.0\n",
    "! export NXF_MODE=google\n",
    "#Install nexflow, make it exceutable, and update it\n",
    "! curl https://get.nextflow.io | bash\n",
    "! chmod +x nextflow\n",
    "! ./nextflow self-update"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73b5bf4-3e68-44c2-9874-02c637e730bf",
   "metadata": {},
   "source": [
    "### Submit Hello World to Batch Directly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f6045f-3336-46ae-917c-6528b4c0c0db",
   "metadata": {},
   "source": [
    "#### Submitting a job through the command line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c12fe3-0635-4e38-8153-51b60ff287ef",
   "metadata": {},
   "source": [
    "To submit a batch job through the command line you first need to create a __json__ file this is your config file. You can use the below hello world script as a template for your batch job. We will name the file hello-world.json.\n",
    "\n",
    "```\n",
    "{\n",
    "    \"taskGroups\": [\n",
    "        {\n",
    "            \"taskSpec\": {\n",
    "                \"runnables\": [\n",
    "                    {\n",
    "                        \"container\": {\n",
    "                            \"imageUri\": \"gcr.io/google-containers/busybox\",\n",
    "                            \"entrypoint\": \"/bin/sh\",\n",
    "                            \"commands\": [\n",
    "                                \"-c\",\n",
    "                                \"echo Hello world! This is task ${BATCH_TASK_INDEX}. This job has a total of ${BATCH_TASK_COUNT} tasks >> /mnt/disks/gbatch-nextflow/hello-world.txt\"\n",
    "                            ]\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "                \"volumes\": [\n",
    "                    {\n",
    "                        \"gcs\": {\n",
    "                            \"remotePath\": \"gbatch-nextflow\"\n",
    "                        },\n",
    "                        \"mountPath\": \"/mnt/disks/gbatch-nextflow\"\n",
    "                    }\n",
    "                ],\n",
    "                \n",
    "                \"computeResource\": {\n",
    "                    \"cpuMilli\": 2000,\n",
    "                    \"memoryMib\": 16\n",
    "                },\n",
    "                \"maxRetryCount\": 2,\n",
    "                \"maxRunDuration\": \"3600s\"\n",
    "            },\n",
    "            \"taskCount\": 4,\n",
    "            \"parallelism\": 2\n",
    "        }\n",
    "    ],\n",
    "    \"allocationPolicy\": {\n",
    "        \"instances\": [\n",
    "            {\n",
    "                \"policy\": { \"machineType\": \"e2-standard-4\" }\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    \"labels\": {\n",
    "        \"department\": \"finance\",\n",
    "        \"env\": \"testing\"\n",
    "    },\n",
    "    \"logsPolicy\": {\n",
    "        \"destination\": \"CLOUD_LOGGING\"\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be843007-486a-433d-bdaf-91aa2168c03d",
   "metadata": {},
   "source": [
    "Let break down the script:\n",
    "- Our image and commands are specified in the block labeled \"container\", imageURI being the theimage busybox and our commands being to echo Hello World.\n",
    "    - You will notice that in the command line we have mounted our bucket this is so our output file hello-world.txt is stored into our bucket __(do not forget to change the mount path to your bucket name)__\n",
    "    - As you noticed there are some variables that we have added these are universal variables that Google has created that dont need to be defined beforehand, they show which task the job is working on presently and how many tasks in total this job has.\n",
    "- Under the 'volume' block this is where we are specifying our Google bucket and the path we are using to mount or join our bucket to our container. __(do not forget to change the mountPath and remotePath to your bucket name)__ \n",
    "- 'compute Resources' is where we define how long the script should run, how many tasks it should have and how many of thoes taks should be run in parallel at a time.\n",
    "- Under 'instances' in our script is where we can specify our machine type.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b76fb0-1b4f-4b43-a27f-6046c3052858",
   "metadata": {},
   "source": [
    "Now we can submit our job specifing title of the job (hello-world) the location (us-central1) and the location of our json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bec6a71-f279-41c1-8965-882612a4095c",
   "metadata": {},
   "outputs": [],
   "source": [
    "! gcloud batch jobs submit hello-world \\\n",
    "  --location us-central1 \\\n",
    "  --config ~/hello-world.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8f7dfd-5a6a-4d04-8325-88e4210cb2c3",
   "metadata": {},
   "source": [
    "#### Submitting a job through the console"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfdaa37-a0d5-44b3-ad4d-dffcd45801f4",
   "metadata": {},
   "source": [
    "Running a batch job through the console allows for a user-friendly view to input data and scripts and view the status of the jobs you created.\n",
    "\n",
    "Start by searching __'Batch'__ in the console search bar you should see a similar setting like this  \n",
    "<img src=\"../../../images/batch_start.png\" width=\"300\" height=\"300\">\n",
    "\n",
    "Near the upper left corner click <img src=\"../../../../images/create.png\" width=\"50\" height=\"50\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c93eae-5424-4d77-9757-9d6cb342986c",
   "metadata": {},
   "source": [
    "The follow should appear on the screen\n",
    " \n",
    " <img src=\"../../../images/create_job_console.png\" width=\"300\" height=\"300\">\n",
    " \n",
    " This is where you can:\n",
    " - Label your job\n",
    " - Select a region and zone to excecute your job\n",
    " - Select your machine type (e.g. e2-medium)\n",
    " - Specify tasks by adding a script and/or specifiying a container to run the task in\n",
    " - Allocating resources for each task\n",
    " - Add storage volume"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c812865a-6ca1-4900-b93f-1239249d952d",
   "metadata": {},
   "source": [
    "Once you have entered the settings for your batch job you can even view the full script that you would submit through the command line by clicking __'EQUIVALENT COMMAND LINE'__ next to __'CREATE'__. Delete the script that is already there and paste the script we had above.\n",
    "\n",
    " <img src=\"../../../images/Batch_command_line_console.png\" width=\"400\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8d633d-88d8-4db5-b834-1ce06e8cd91d",
   "metadata": {},
   "source": [
    "Once you run your job by clicking __'CREATE'__. <br>\n",
    "By clicking the job name you can view more information of the jobs setting, resources applied, and logs by clicking  <img src=\"../../../images/log.png\" width=\"100\" height=\"100\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4892a16-f4d9-4db9-a171-6e9245df2a72",
   "metadata": {},
   "source": [
    "### Check job status\n",
    "\n",
    "You can view the status of your job by looking at the __'Job List'__ in the Google Console. Here you will see your job name, status, region, memory per task, machine type, date started and run time.\n",
    "\n",
    " <img src=\"../../../images/Job_l.png\" width=\"500\" height=\"500\">\n",
    " \n",
    "To check the job status via the command line enter the following changing the job name and location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411b0153-aed6-4694-b54d-af6e80db5726",
   "metadata": {},
   "outputs": [],
   "source": [
    "! gcloud batch jobs describe hello-world \\\n",
    "    --location=LOCATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f056585-6c10-41b6-b7b6-0c75bebed811",
   "metadata": {},
   "source": [
    "### View your output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86e2e14-8efe-4a36-8a5a-9d43407653c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "! gsutil ls gs://$BUCKET/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02faf944-0143-49c7-bf4c-6b8e377fcd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "! gsutil cp gs://$BUCKET/hello_world.txt .\n",
    "! cat hello_world.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a142e0-bd9a-405d-91f9-827503ff5fb1",
   "metadata": {},
   "source": [
    "## Run Nextflow Locally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2457d31d-d8b7-42f1-a0be-0d88c95d4fc3",
   "metadata": {},
   "source": [
    "### Nextflow 101"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b709c718-96d0-4925-99dd-525a7e7b6c76",
   "metadata": {},
   "source": [
    "Nextflow interacts with many different files to have a proper working workflow:\n",
    "\n",
    "- __Main file__: The main file is a .nf file that holds the processes and channels describing the input, output, a shell script of your commands, workflow which acts like a recipe book for nextflow, and/or conditions. For snakemake users this is equivalent to 'rules'.\n",
    "    - __Process__: Contains channels and scripts that can be executed in a Linux server like bash commands.\n",
    "    - __Channel__: Produces ways through which processes communicate to each other for example input and output are channels of value that point the process to where data is or should be located.\n",
    "- __Config file__: The .config file contains parameters, and multiple profiles. Each profile can contain a different executor type (e.g. LS API, conda, docker, etc.), memory or machine type, output directory, working directory and more!\n",
    "- __Docker file__: Contains dependencies and enviroments that is needed for the nextflow workflow to run.\n",
    "- __Schema file__: Schmema files are optional and are structured json files that contain information about the usage and commands that your workflow will excecute.You might have seen this when you run a command along with the flag '--help'.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bea3004-ff40-4918-ac16-83aad9427ad7",
   "metadata": {},
   "source": [
    "### Run a nextflow 'Hello World' process locally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4715ef92-e3a6-44cf-9b1e-50f247dd0daf",
   "metadata": {},
   "source": [
    "We are going to first run Hello World locally using the config file called hello.nf. \n",
    "\n",
    "It should look like this:\n",
    "\n",
    "```\n",
    "#!/usr/bin/env nextflow\n",
    "nextflow.enable.dsl=2 \n",
    "\n",
    "params.str = 'Hello World'\n",
    "\n",
    "process sayHello {\n",
    "  input:\n",
    "  val str\n",
    "\n",
    "  output:\n",
    "  stdout\n",
    "\n",
    "  \"\"\"\n",
    "  echo $str > hello.txt\n",
    "  cat hello.txt\n",
    "  \"\"\"\n",
    "}\n",
    "workflow {\n",
    "  sayHello(params.str) | view\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efad386-185b-4faf-be39-6c5a3f84ffe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ./nextflow run hello.nf --str 'Hello!'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7619875d-7f10-4699-b4d2-120d5d7d4cd7",
   "metadata": {},
   "source": [
    "## Submit Nextflow Job to the Google Batch\n",
    "Create and modify your own config file to include a 'gbatch' profile block to tell Nextflow to submit the job to Google Batch instead of running locally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7abe9b-dca1-4ef6-87d6-39fcdd2e3c9b",
   "metadata": {},
   "source": [
    "The config file allows nextflow to utilize excecuters like Google Batch. In this tutorial the config files is named __'nextflow.config'__. Make sure you open this file and update the `<VARIABLES>` that are account specific.\n",
    "- Make sure that your region is a region included in the Google Batch!\n",
    "- Specify your working directory bucket and output directory bucket\n",
    "- Specify the machine type you would like to use, ensuring that there is enough memory and cpus for the workflow\n",
    "    - Otherwise Google Batch will automatically use 1 CPU\n",
    "\n",
    "```\n",
    "profiles{\n",
    "  gbatch{\n",
    "      process.executor = 'google-batch'\n",
    "      workDir = 'gs://<BUCKET>/methyl-seq'\n",
    "      google.location = 'us-central1'\n",
    "      google.region  = 'us-central1'\n",
    "      google.project = '<YOUR_PROJECT>'\n",
    "      params.outdir = 'gs://<BUCKET>methyl-seq/outdir'\n",
    "      process.machineType = 'c2-standard-30'\n",
    "     }\n",
    "}\n",
    "```\n",
    "\n",
    "__Note:__ Make sure your working directory and output directory are different! Google Batch creates temporary file in the working directory within your bucket that do take up space so once your pipeline has completed succesfully feel free to delete the temporary files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340f7300-449a-4a12-bbc5-073547d58cac",
   "metadata": {},
   "source": [
    "### Optional: Listing nf-core tools with docker and viewing their commands\n",
    "Using the command below you can see all the tools that nfcore holds and their versions/lastes releases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1ff164-cee2-446e-ab2e-a3ed984e0dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "! docker run nfcore/tools list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e46373c-61d0-4c91-b001-e55568d9fa2d",
   "metadata": {},
   "source": [
    "You can view commands for methylseq (or any other specified nf-core tool) by using the [--help] flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ea2893-60b3-4934-ae86-b07d4bc59728",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ./nextflow run nf-core/methylseq -r 1.6.1 --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dbef59-d619-4444-8870-18c1f0ba3b5c",
   "metadata": {},
   "source": [
    "### Run Methylseq with the test profile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7238bd3e-1853-42c3-9d2d-c72e46975ff2",
   "metadata": {},
   "source": [
    "The 'test' profile uses a small dataset allowing you to ensure the workflow works with your config file without long runtimes. Ensure you include:\n",
    "- Version of the nf-core tool [-r]\n",
    "- Location of the config file [-c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b21f170-37fa-4fbc-ab83-3f6b4d386ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ./nextflow run nf-core/methylseq -r 1.6.1 -profile test,gbatch -c nextflow-methyseq.config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e386ccb3-aa6d-4a77-8d7d-c20ed0419f84",
   "metadata": {},
   "source": [
    "You will notice in the above that to the left of the process within the __[ ]__ is actually a __tag__ you can search in Google Batch and the text before the __/__ corresponds to the __temporary directories__ within your working directory. Feel free to delete the temporary directories once your workflow has succesfully completed.\n",
    "\n",
    "Congrats! You are done with Part I. If you want to keep going and learn how to use the Methylseq workflow with real data, then move to Part II. If not, then feel free to clean up your resources. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d5ad01-cc27-4407-8434-b88d324b9e2c",
   "metadata": {},
   "source": [
    "## Troubleshooting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79edcad-7178-4219-b097-e9b21b98bcc7",
   "metadata": {},
   "source": [
    "Some of the nf-core tools require extra parameters:\n",
    "- If you receive a error of __'quota exceeded'__ error you can increase your boot disk size to the gbatch profile within your config file using the __google.batch.bootDiskSize__ parameter (e.g., google.batch.bootDiskSize = 100.GB)\n",
    "- Some errors show that a tool could not be used, was not installed, or gives a error that doesn't really explain the reason for why the process stopped you can try to increase the process time on your profile by using the __process.time parameter__ (e.g., process.time = '2h')\n",
    "- If you receive a error like below using the new release of Nextflow should fix this v23.04.0 or later\n",
    "```\n",
    "Caused by:\n",
    "  Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@49b3a025[Not completed, task = java.util.concurrent.Executors$RunnableAdapter@2e0ceb8c[Wrapped task = TrustedListenableFutureTask@25c1396d[status=PENDING, info=[task=[running=[NOT STARTED YET], com.google.api.gax.rpc.AttemptCallable@2db57b9a]]]]] rejected from java.util.concurrent.ScheduledThreadPoolExecutor@aa6214[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]\n",
    "\n",
    "```\n",
    "- adding the __-log parameter__ on the command line will help produce a log file that will help to troubleshoot other errors like so: \n",
    "`./nextflow -log DIRECTORY_NAME/nextflow.log run <process name>`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e245825",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Here you learned how to run Nextflow locally, submit a test job to Google Batch, and then to submit a Nextflow job to Google Batch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bf5cba-995d-4404-94d1-9bc9c4a04482",
   "metadata": {},
   "source": [
    "## Clean up\n",
    "If you want to clean up all resources associated with this tutorial then \n",
    "+ delete your bucket with `gsutil rm -r $BUCKET`\n",
    "+ delete this VM in either Vertex AI or Compute Engine"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}

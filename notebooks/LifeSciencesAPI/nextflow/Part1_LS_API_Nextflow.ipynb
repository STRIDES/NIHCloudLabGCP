{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5cdaee0-cc9d-430a-8d95-6af15b2534a8",
   "metadata": {},
   "source": [
    "# Use Nextflow to run workflows using the Cloud Life Sciences API Part I\n",
    "\n",
    "## Overview\n",
    "Here we are going to walk through submitting simple jobs directly to the Life Sciences API, then dive into interacting with the API using Nextflow. We will run some basic Hello World jobs, then move to a more complex [nf-core Methylseq workflow](https://nf-co.re/methylseq). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5aa78f4-b8f7-4fbd-846c-09142ac36891",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\"> <b>Warning:</b> Google Life Sciences API is depreciated and will no longer be avaible by July 8, 2025 on the platform. Please switch to the <a href=\"../../GoogleBatch/nextflow/Part1_GBatch_Nextflow.ipynb\">Google Batch Nextflow tutorials</a>. </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe82256",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "+ Learn to use Nextflow on Google Cloud\n",
    "+ Learn to submit Nextflow jobs to Google Life Sciences API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69387ba0",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "Make sure that Cloud Life Sciences, Compute Engine, and Cloud Storage APIs are all enabled.\n",
    "\n",
    "You also want to make sure your Compute Engine Default Service Account has the following Roles:\n",
    "\n",
    "    - lifesciences.workflowsRunner\n",
    "    - iam.serviceAccountUser\n",
    "    - serviceusage.serviceUsageConsumer\n",
    "    - storage.objectAdmin\n",
    "Your Service Account should already have these roles assigned, but if not, reach out to Support to have your account updated.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538cfc56",
   "metadata": {},
   "source": [
    "## Get Started"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8f4b85-9459-497d-97ec-5909e8aeacae",
   "metadata": {},
   "source": [
    "### Install packages and setup your environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e4a5ca-8a2b-4156-b83e-c89f0c1ffc9c",
   "metadata": {},
   "source": [
    "#### Create a bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c79eb1-6010-4d8a-8725-b92144bab944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure you change this name, it needs to be globally unique\n",
    "%env BUCKET=gls-api-nextflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d17e57-86e8-4fce-83fe-3c33c7db9dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# will only create the bucket if it doesn't yet exist\n",
    "! gsutil ls gs://$BUCKET >& /dev/null || gsutil mb gs://$BUCKET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553761fd-4ce3-4dda-8319-a10cb9cd5314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set versioning on the bucket so it can overwrite old files\n",
    "! gsutil versioning set on gs://$BUCKET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d588a5-83b2-42ef-a65f-64b2c80bca3f",
   "metadata": {},
   "source": [
    "#### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acefde5-3f8a-42cb-aa12-46396eaae644",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First install java\n",
    "!sudo apt update\n",
    "!sudo apt-get install default-jdk -y\n",
    "!java -version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8538e0-49a3-4e61-abf3-a08e1b397fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify nexflow version and platfrom\n",
    "! export NXF_VER=21.10.0\n",
    "! export NXF_MODE=google\n",
    "#Install nexflow, make it exceutable, and update it\n",
    "! curl https://get.nextflow.io | bash\n",
    "! chmod +x nextflow\n",
    "! ./nextflow self-update"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73b5bf4-3e68-44c2-9874-02c637e730bf",
   "metadata": {},
   "source": [
    "## Submit Hello World to the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb5bd4b-032a-47f0-bee4-299a547c3b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "! gcloud beta lifesciences pipelines run \\\n",
    "    --location us-central1 \\\n",
    "    --regions us-east1 \\\n",
    "    --logging gs://$BUCKET/hello_world.log \\\n",
    "    --command-line 'echo \"hello world!\"'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4892a16-f4d9-4db9-a171-6e9245df2a72",
   "metadata": {},
   "source": [
    "### Check job status\n",
    "To check the job status enter operation ID from the gcloud output\n",
    "\n",
    "Running [projects/PROJECT_ID/locations/LOCATION/operations/OPERATION_ID]\n",
    "The output is kind of hard to parse, but it starts at the bottom, the top is the most recent action. If you have an error, it should be towards the top. Even for this simple job, it may take a few minutes to finish all operations, so keep checking until it says `done: true` at the top. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa92ba73-13c8-4e90-9c41-61a6fb84bf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set your operation ID here\n",
    "%env ID=10485099716669037373"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cba7c4e-4b8c-4e4c-80e4-8de1f11b5790",
   "metadata": {},
   "outputs": [],
   "source": [
    "! gcloud beta lifesciences operations describe $ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f056585-6c10-41b6-b7b6-0c75bebed811",
   "metadata": {},
   "source": [
    "### View your output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86e2e14-8efe-4a36-8a5a-9d43407653c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "! gsutil ls gs://$BUCKET/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02faf944-0143-49c7-bf4c-6b8e377fcd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "! gsutil cp gs://$BUCKET/hello_world.log .\n",
    "! cat hello_world.log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a142e0-bd9a-405d-91f9-827503ff5fb1",
   "metadata": {},
   "source": [
    "## Run Nextflow Locally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2457d31d-d8b7-42f1-a0be-0d88c95d4fc3",
   "metadata": {},
   "source": [
    "### Nextflow 101"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b709c718-96d0-4925-99dd-525a7e7b6c76",
   "metadata": {},
   "source": [
    "Nextflow interacts with many different files to have a proper working workflow:\n",
    "\n",
    "- __Main file__: The main file is a .nf file that holds the processes and channels describing the input, output, a shell script of your commands, workflow which acts like a recipe book for nextflow, and/or conditions. For snakemake users this is equivalent to 'rules'.\n",
    "    - __Process__: Contains channels and scripts that can be executed in a Linux server like bash commands.\n",
    "    - __Channel__: Produces ways through which processes communicate to each other for example input and output are channels of value that point the process to where data is or should be located.\n",
    "- __Config file__: The .config file contains parameters, and multiple profiles. Each profile can contain a different executor type (e.g. LS API, conda, docker, etc.), memory or machine type, output directory, working directory and more!\n",
    "- __Docker file__: Contains dependencies and enviroments that is needed for the nextflow workflow to run.\n",
    "- __Schema file__: Schmema files are optional and are structured json files that contain information about the usage and commands that your workflow will excecute.You might have seen this when you run a command along with the flag '--help'.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bea3004-ff40-4918-ac16-83aad9427ad7",
   "metadata": {},
   "source": [
    "### Run a nextflow 'Hello World' process locally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4715ef92-e3a6-44cf-9b1e-50f247dd0daf",
   "metadata": {},
   "source": [
    "We are going to first run Hello World locally using the config file called hello.nf. \n",
    "\n",
    "It should look like this:\n",
    "\n",
    "```\n",
    "#!/usr/bin/env nextflow\n",
    "nextflow.enable.dsl=2 \n",
    "\n",
    "params.str = 'Hello World'\n",
    "\n",
    "process sayHello {\n",
    "  input:\n",
    "  val str\n",
    "\n",
    "  output:\n",
    "  stdout\n",
    "\n",
    "  \"\"\"\n",
    "  echo $str > hello.txt\n",
    "  cat hello.txt\n",
    "  \"\"\"\n",
    "}\n",
    "workflow {\n",
    "  sayHello(params.str) | view\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efad386-185b-4faf-be39-6c5a3f84ffe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ./nextflow run hello.nf --str 'Hello!'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7619875d-7f10-4699-b4d2-120d5d7d4cd7",
   "metadata": {},
   "source": [
    "## Submit Nextflow Job to the Life Sciences API\n",
    "Create and modify your own config file to include a 'gls' profile block to tell Nextflow to submit the job to the API instead of running locally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7abe9b-dca1-4ef6-87d6-39fcdd2e3c9b",
   "metadata": {},
   "source": [
    "The config file allows nextflow to utilize excecuters like Life Science API. In this tutorial the config files is named __'nextflow.config'__. Make sure you open this file and update the `<VARIABLES>` that are account specific.\n",
    "- Make sure that your region is a region included in the LS API!\n",
    "- Specify your working directory bucket and output directory bucket\n",
    "- Specify the machine type you would like to use, ensuring that there is enough memory and cpus for the workflow\n",
    "    - Otherwise LS API will automatically use 1 CPU\n",
    "\n",
    "```\n",
    "profiles{\n",
    "  gls{\n",
    "      process.executor = 'google-lifesciences'\n",
    "      workDir = 'gs://<BUCKET>/methyl-seq'\n",
    "      google.location = 'us-central1'\n",
    "      google.region  = 'us-central1'\n",
    "      google.project = '<YOUR_PROJECT>'\n",
    "      params.outdir = 'gs://<BUCKET>methyl-seq/outdir'\n",
    "      process.machineType = 'c2-standard-30'\n",
    "     }\n",
    "}\n",
    "```\n",
    "\n",
    "__Note:__ Make sure your working directory and output directory are different! Life Sciences creates temporary file in the working directory within your bucket that do take up space so once your pipeline has completed succesfully feel free to delete the temporary files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340f7300-449a-4a12-bbc5-073547d58cac",
   "metadata": {},
   "source": [
    "### Optional: Listing nf-core tools with docker and viewing their commands\n",
    "Using the command below you can see all the tools that nfcore holds and their versions/lastes releases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1ff164-cee2-446e-ab2e-a3ed984e0dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "! docker run nfcore/tools list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e46373c-61d0-4c91-b001-e55568d9fa2d",
   "metadata": {},
   "source": [
    "You can view commands for methylseq (or any other specified nf-core tool) by using the [--help] flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ea2893-60b3-4934-ae86-b07d4bc59728",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ./nextflow run nf-core/methylseq -r 1.6.1 --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dbef59-d619-4444-8870-18c1f0ba3b5c",
   "metadata": {},
   "source": [
    "### Run Methylseq with the test profile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7238bd3e-1853-42c3-9d2d-c72e46975ff2",
   "metadata": {},
   "source": [
    "The 'test' profile uses a small dataset allowing you to ensure the workflow works with your config file without long runtimes. Ensure you include:\n",
    "- Version of the nf-core tool [-r]\n",
    "- Location of the config file [-c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b21f170-37fa-4fbc-ab83-3f6b4d386ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ./nextflow run nf-core/methylseq -r 1.6.1 -profile test,gls -c nextflow-methyseq.config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e386ccb3-aa6d-4a77-8d7d-c20ed0419f84",
   "metadata": {},
   "source": [
    "You will notice in the above that to the left of the process within the __[ ]__ is actually a __tag__ you can search in Life Sciences and the text before the __/__ corresponds to the __temporary directories__ within your working directory. Feel free to delete the temporary directories once your workflow has succesfully completed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8686bbae",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Congrats! You are done with Part I. If you want to keep going and learn how to use the Methylseq workflow with real data, then move to Part II. If not, then feel free to clean up your resources. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bf5cba-995d-4404-94d1-9bc9c4a04482",
   "metadata": {},
   "source": [
    "## Clean up\n",
    "If you want to clean up all resources associated with this tutorial then \n",
    "+ delete your bucket with `gsutil rm -r $BUCKET`\n",
    "+ delete this VM in either Vertex AI or Compute Engine"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
